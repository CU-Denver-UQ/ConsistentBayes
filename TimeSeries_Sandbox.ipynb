{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Time-Series Data in a Consistent Bayesian Framework\n",
    "---\n",
    "\n",
    "Copyright 2017 Michael Pilosov\n",
    "\n",
    "Demonstration available at https://www.youtube.com/watch?v=rUIVcl64NXw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_(should be 2.7 and 3.x compatible) _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interactivity\n",
    "from ipywidgets import *\n",
    "from cb_sandbox import *\n",
    "%matplotlib inline\n",
    "\n",
    "def make_tabulated_sandbox(num_experiments=1):\n",
    "    # We create many copies of the same widget objects in order to isolate our experimental areas.\n",
    "    num_samples = [widgets.IntSlider(value=2500, continuous_update=False, \n",
    "        orientation='vertical', disable=False,\n",
    "        min=int(5E2), max=int(2.5E4), step=500, \n",
    "        description='Samples $N$') for k in range(num_experiments)]\n",
    "\n",
    "    sd = [widgets.FloatSlider(value=0.25, continuous_update=False, \n",
    "        orientation='vertical', disable=False,\n",
    "        min=0.05, max=1.75, step=0.05, \n",
    "        description='Const. $\\sigma$') for k in range(num_experiments)]\n",
    "\n",
    "    lam_min, lam_max = 2.0, 7.0\n",
    "    lam_bound = [widgets.FloatRangeSlider(value=[3.0, 6.0], continuous_update=False, \n",
    "        orientation='horizontal', disable=False,\n",
    "        min=lam_min, max = lam_max, step=0.5, \n",
    "        description='Param: $\\Lambda \\in$') for k in range(num_experiments)]\n",
    "\n",
    "    lam_0 = [widgets.FloatSlider(value=4, continuous_update=False, \n",
    "        orientation='horizontal', disable=False,\n",
    "        min=lam_bound[k].value[0], max=lam_bound[k].value[1], step=0.1, \n",
    "        description='IC: $\\lambda_0$') for k in range(num_experiments)]\n",
    "\n",
    "\n",
    "    t_0 = [widgets.FloatSlider(value=0.5, continuous_update=False, \n",
    "        orientation='horizontal', disable=False,\n",
    "        min=0.1, max=2.0, step=0.1,\n",
    "        description='$t_0$ =', readout_format='.1f') for k in range(num_experiments)]\n",
    "\n",
    "    Delta_t = [widgets.FloatSlider(value=0.1, continuous_update=False, \n",
    "        orientation='horizontal', disable=False,\n",
    "        min=0.05, max=0.5, step=0.05,\n",
    "        description='$\\Delta_t$ =', readout_format='.2f') for k in range(num_experiments)]\n",
    "\n",
    "    num_observations = [widgets.IntSlider(value=50, continuous_update=False, \n",
    "        orientation='horizontal', disable=False,\n",
    "        min=1, max=100, \n",
    "        description='# Obs. =') for k in range(num_experiments)]\n",
    "    \n",
    "    compare = [widgets.Checkbox(value=False, disable=False,\n",
    "        description='Observed v. Q(Post)') for k in range(num_experiments)]\n",
    "    \n",
    "    smooth_post = [widgets.Checkbox(value=False, disable=False,\n",
    "        description='Smooth Posterior') for k in range(num_experiments)]\n",
    "    \n",
    "    fixed_noise = [widgets.Checkbox(value=False, disable=False,\n",
    "        description='Fixed Noise Model') for k in range(num_experiments)]\n",
    "    \n",
    "    num_trials = [widgets.IntSlider(value=1, continuous_update=False, \n",
    "        orientation='vertical', disable=False,\n",
    "        min=1, max=25, \n",
    "        description='Num. Trials') for k in range(num_experiments)]\n",
    "    \n",
    "    Keys = [{'num_samples': num_samples[k], \n",
    "            'lam_bound': lam_bound[k], \n",
    "            'lam_0': lam_0[k], \n",
    "            't_0': t_0[k], \n",
    "            'Delta_t': Delta_t[k],\n",
    "            'num_observations': num_observations[k], \n",
    "            'sd': sd[k],\n",
    "            'compare': compare[k],\n",
    "            'smooth_post': smooth_post[k],\n",
    "            'fixed_noise': fixed_noise[k],\n",
    "            'num_trials': num_trials[k]} for k in range(num_experiments)] \n",
    "\n",
    "    # Make all the interactive outputs for each tab and store them in a vector called out. (for output)\n",
    "    out = [interactive_output(sandbox, Keys[k]) for k in range(num_experiments)]\n",
    "    \n",
    "    \n",
    "    ### LINK WIDGETS TOGETHER (dependent variables) ###\n",
    "    # if you change the bounds on the parameter space, update the bounds of lambda_0                          \n",
    "    def update_lam_0(*args):\n",
    "        k = tab_nest.selected_index\n",
    "    #     lam_0[k].value = np.minimum(lam_0[k].value, lam_bound[k].value[1] )\n",
    "    #     lam_0[k].value = np.maximum(lam_0[k].value, lam_bound[k].value[0] )\n",
    "        lam_0[k].min = lam_bound[k].value[0] \n",
    "        lam_0[k].max = lam_bound[k].value[1]\n",
    "\n",
    "    [lam_bound[k].observe(update_lam_0, 'value') for k in range(num_experiments)]\n",
    "\n",
    "\n",
    "    ### GENERATE USER INTERFACE ###\n",
    "    lbl = widgets.Label(\"UQ Sandbox\", disabled=False)\n",
    "    # horizontal and vertical sliders are grouped together, displayed in one horizontal box.\n",
    "    # This HBox lives in a collapsable accordion below which the results are displayed.\n",
    "    h_sliders = [widgets.VBox([lam_bound[k], lam_0[k], \n",
    "                               t_0[k], Delta_t[k], \n",
    "                               num_observations[k] ]) for k in range(num_experiments) ]\n",
    "    v_sliders = [widgets.HBox([ num_samples[k], num_trials[k],\n",
    "                               sd[k] ]) for k in range(num_experiments) ]\n",
    "    options = [ widgets.VBox([widgets.Text('Model Options', disabled=True), \n",
    "                              fixed_noise[k],\n",
    "                              widgets.Text('Plotting Options', disabled=True), \n",
    "                              compare[k], smooth_post[k]]) for k in range(num_experiments)]\n",
    "    user_interface = [widgets.HBox([h_sliders[k], options[k], v_sliders[k]]) for k in range(num_experiments)]\n",
    "    \n",
    "    # format the widgets layout (non-default options)\n",
    "    for k in range(num_experiments): \n",
    "        h_sliders[k].layout.justify_content = 'center'\n",
    "        v_sliders[k].layout.justify_content = 'center'\n",
    "        user_interface[k].layout.justify_content = 'center'\n",
    "\n",
    "        \n",
    "    ### MAKE TABULATED NOTEBOOK ###\n",
    "    # Create our pages\n",
    "    pages = [widgets.HBox() for k in range(num_experiments)]\n",
    "\n",
    "    # instantiate notebook with tabs (accordions) representing experiments\n",
    "    tab_nest = widgets.Tab()\n",
    "    tab_nest.children = [pages[k] for k in range(num_experiments)]\n",
    "\n",
    "    # title your notebooks\n",
    "    experiment_names = ['Experiment %d'%k for k in range(num_experiments)]\n",
    "    for k in range(num_experiments):\n",
    "        tab_nest.set_title(k, experiment_names[k])\n",
    "\n",
    "    # Spawn the children!!!\n",
    "    for k in range(num_experiments):\n",
    "    #     content = widgets.VBox( [user_interface[k], out[k]] )\n",
    "        A = widgets.Accordion(children=[ user_interface[k] ])\n",
    "        A.set_title(0,lbl.value)\n",
    "        A.layout.justify_content = 'center'\n",
    "        content = widgets.VBox([ A, out[k]  ])\n",
    "        content.layout.justify_content = 'center'\n",
    "        tab_nest.children[k].children = [content]\n",
    "    \n",
    "    return tab_nest\n",
    "\n",
    "# define wrapper function to repeat trials. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Defining the Parameter to Observables (PtO) and Quantity of Interest (QoI) maps\n",
    "\n",
    "---\n",
    "Consider the Initival Value Problem (IVP)\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "    \\dot{u}(t) = -u(t), & t>0 \\\\\n",
    "    u(0) = \\lambda, & \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "with solution $u(t;\\lambda) = \\lambda \\,e^{-t}$.\n",
    "\n",
    "Let $0<t_0<t_1<\\ldots, t_K$ denote the observation times. \n",
    "Given a fixed initial condition (i.e., parameter) $\\lambda$, let $y_k$ denote the set of (noisy) observations of the state variable $u(t_k,\\lambda)$ for $k=0,1,\\ldots, K$. \n",
    "\n",
    "We make the standard assumption of an additive error model with independent identically distributed noise, i.e., for each $k=0,1,\\ldots,K$ and fixed value of $\\lambda$, we assume that the Parameter-to-Observables (PtO) maps are given by\n",
    "\n",
    "$$\n",
    "O_k(\\lambda) := u(t_k;\\lambda) + \\epsilon_k, \\quad \\epsilon_k \\sim N(0,\\sigma_k). \n",
    "$$\n",
    "\n",
    "Assume that there is a true value of $\\lambda$, which we denoted by $\\lambda_0$, for which the observations $y_k:=O_k(\\lambda_0)$ are given for $k=0,1,\\ldots,K$.\n",
    "\n",
    "Then, for any other value of $\\lambda$ in the IVP above, we define the Quantity of Interest (QoI) as the **Weighted Sum Squared Error (a weighted 2-norm) between the observations and the model predictions**, i.e., we define the QoI map as\n",
    "\n",
    "$$\n",
    "    \\boxed{Q(\\lambda) := \\sum_{k=0}^{K} \\frac{(u(t_k;\\lambda) - y_k) ^ 2}{\\sigma_k^2}}\n",
    "$$\n",
    "\n",
    "We let $\\mathcal{D} := Q(\\Lambda)$ denote the space of all possible observations of mean squared error. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Formulating the Inverse Problem:\n",
    "---\n",
    "### Prior Information/Assumptions\n",
    "\n",
    "* We assume that the true value $\\lambda_0$ belongs to the parameter space defined by $\\Lambda:= [0, 2]$.\n",
    "\n",
    "\n",
    "* Prior to the data $\\{y_k\\}_{k=0}^K$ being available, any value of the parameter $\\lambda$ in $\\Lambda$ is assumed to be equally likely. In other words, we take $\\pi^{prior}_\\Lambda(\\lambda)$ to be a uniform density.\n",
    "\n",
    "\n",
    "### The Observed Density\n",
    "\n",
    "* For the true value of $\\lambda_0$, we have that $u(t_k;\\lambda_0)-y_k = \\epsilon_k$ for each $k$. Thus, the observed density on $\\mathcal{D}$, denoted by $\\pi^{obs}_{\\mathcal{D}}(d)$, is given by a $\\chi^2_{K+1}$ distribution.\n",
    "\n",
    "### The Posterior Density\n",
    "\n",
    "* Let $\\pi^{O(prior)}_{\\mathcal{D}}(d)$ denote the push-forward of the prior density onto $\\mathcal{D}$. Then, the posterior density on $\\Lambda$ is given by\n",
    "\n",
    "$$\n",
    "    \\pi^{post}_\\Lambda(\\lambda) := \\pi^{prior}_\\Lambda(\\lambda)\\frac{\\pi^{obs}_{\\mathcal{D}}(Q(\\lambda))}{\\pi^{O(prior)}_{\\mathcal{D}}(Q(\\lambda))}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## The numerical implementation and practical considerations\n",
    "---\n",
    "Here, we provide only a few brief remarks on the implementation.\n",
    "For a step-by-step walkthrough, please see the CBayes_TS.ipynb file.\n",
    "Below you will find an all-in-one version. \n",
    "\n",
    "***Some useful remarks go here.***\n",
    "\n",
    "* In the `sandbox` function below, `T` is an interval of observation times\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Define some functions for the sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# All-in-One Sandbox!\n",
    "_Run the cells below to start experimenting_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the \"tabulated nest\"\n",
    "num_experiments = 1\n",
    "tab_nest = make_tabulated_sandbox(num_experiments)\n",
    "tab_nest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you find some parameters you like, you can run multiple instances of it below to get a sense of the variations in the solutions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact_manual(sandbox, \n",
    "        num_samples = IntSlider(value=2500, \n",
    "            min=int(5E2), max=int(5E4), step=500, description='Samp. $N$ ='), \n",
    "        lam_bound = FloatRangeSlider(value=[3.0, 6.0], \n",
    "            min=2.0, max = 7.0, step=0.5, description='Param $\\Lambda \\in$'),\n",
    "        lam_0 = FloatSlider(value=3.5, \n",
    "            min=2.0, max=7.0, step=0.1, description='IC: $\\lambda_0$ ='), \n",
    "        t_0 = FloatSlider(value=0.5, \n",
    "            min=0.1, max=2, step=0.1, description='$t_0$ ='),\n",
    "        Delta_t = FloatSlider(value=0.1, \n",
    "            min=0.05, max=0.5, step=0.05, description='$\\Delta_t$ ='),\n",
    "        num_observations = IntSlider(value=50, \n",
    "            min=1, max=100, description='# of Obs. ='), \n",
    "        sd = FloatSlider(value=0.1, \n",
    "            min=0.05, max=0.25, step=0.01, description='Constant $\\sigma$:'), \n",
    "        fixed_noise=fixed(True), \n",
    "        compare = fixed(False),\n",
    "        smooth_post = fixed(False)); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Suggestions\n",
    "\n",
    "- Increase $N$ and watch the Pushforward of the Prior change/converge.\n",
    "- If you broaden the standard deviation $\\sigma$, we suggest to also broaden the bound on the parameter space $\\Lambda$ in order to avoid voilating the predictability assumption.\n",
    "- Notice the relationship between the bound on the interval we are inverting for the Mean Squared Error and the support of the posterior.\n",
    "- The same happens as you increase $\\sigma$.\n",
    "- Change the initial condition $\\lambda_0$ and watch the posterior distribution follow the slider.\n",
    "\n",
    "\n",
    "\n",
    "- Fix the number of observations to 1 and change the interval over which the observation is being made (with $K=0$, the observation occurs only at $T_0$). Notice the diminishing returns as you wait to make your measurement. \n",
    "- Fix some interval and change the number of observations made during this time period.\n",
    "- Fix a number of observations (several) and fix $T_0$ while changing $T$ to observe another example of diminshing returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Entropy barely changes as $\\lambda_0$ moves around. Increases a bit near boundary of $\\Lambda$ (likely due to predictability assumption being violated)\n",
    "- For a wide time measurement window, entropy increases with the number of observations (d.o.f.)\n",
    "- Widening $\\Lambda$ decreases entropy, obviously enlarges $\\mathcal{D}$, support of $P_\\mathcal{D}$.\n",
    "- If you narrow the window, the entropy decreases.\n",
    "- As the window slides earlier in time, the entropy decreases.\n",
    "- Higher MSE threshold ($\\epsilon$, support of observed density) means higher entropy.\n",
    "- Higher variance means higher entropy. We might run a suite of $\\sigma$s MADS-style to study the robustness of a design. \n",
    "    - perhaps if we try to minimize entropy (maximize information gain), we look for designs that are less sensitive to the choice of $\\sigma$s, which would **correspond to an experimental design that is robust to measurement uncertainty.**\n",
    "- Increasing the number of samples $N$ increases entropy quite a bit. Would like to figure out a way to control for this? _Is it even right to be using `scipy.stats.entropy`?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {
    "c4141ec5ed104fa18753136137c56223": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
