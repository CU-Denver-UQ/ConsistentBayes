{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries for Math, Distributions, Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "from scipy.stats import uniform\n",
    "# from scipy.stats import chi2\n",
    "from scipy.stats import gaussian_kde as gkde\n",
    "from scipy.stats import multivariate_normal\n",
    "# import scipy.stats as sstats \n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(skew_range):\n",
    "    # this function makes a linear map whos first component is the x-unit vector\n",
    "    # and each subsequent component is a norm-1 vector satisfying the property\n",
    "    # that the 2-2 map made from it and the aforementioned unit vector is a map\n",
    "    # with skewness in skew_range, which is a list of desired skewnesses   \n",
    "    # TODO currently this map only works for 2-D input space     \n",
    "    \n",
    "    def my_model(parameter_samples):\n",
    "        Q_map = [ [1.0, 0.0] ] # all map components have the same norm, rect_size to have measures of events equal btwn spaces.\n",
    "        for s in skew_range:\n",
    "            Q_map.append( [np.sqrt(s**2 - 1), 1] ) # taken with the first component, this leads to a 2-2 map with skewsness 's'\n",
    "        Q_map = np.array( Q_map )\n",
    "        QoI_samples = np.dot(parameter_samples, np.transpose(Q_map))\n",
    "        return QoI_samples\n",
    "    return my_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Simulation Options\n",
    "\n",
    "We are trying to determine the relationship between skewness and the number of samples required to approximate a solution to the inverse problem according to the $L^1$ metric (Total Variation).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_ref = np.array([0.5, 0.5])\n",
    "num_samples = np.array([1E2, 1E3, 1E4, 1E5]).astype('int') # independent variable\n",
    "\n",
    "# Number of Samples used for reference solution, number of trials\n",
    "num_trials = 5\n",
    "num_emulate = int(1E6)\n",
    "\n",
    "# define some handles for functions we will use.\n",
    "# prior_dist = np.random.uniform\n",
    "prior_dist = uniform # can use any scipy.stats class\n",
    "obs_dens = multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "skew_range = np.array([1, 2, 4]) # skewnesses you want to compare\n",
    "sigma = 1E-3\n",
    "scale = 0.2\n",
    "N = 2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Familiarize yourself with how the `make_model` function works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us also familiarize ourselves with our observed density of choice and make sure we are not going to violate the predictability assumption. As skewness increases, it becomes necessary to lower the covariance of our observed density in order to prevent violation of the predictability assumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do note that the uniform pdf has a bit of an interesting trick to get the pdf properly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = uniform(loc=q_center-0.5*scale, scale=scale)\n",
    "x = np.array( [[0.5, 1.3], [0.5, 1.4], [0.5, 1.5]] )\n",
    "np.prod(a.pdf( x ), axis=1) # we have to do this... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whereas we can just do the following if our observed distribution object already has built-in support for multivariate cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = multivariate_normal(mean=q_center, cov=sigma)\n",
    "b.pdf(x) # instead of simply this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewness = skew_range[1]\n",
    "\n",
    "lam = prior_dist.rvs( size=(N, 2) ) # this is how we'll call the syntax later on as well\n",
    "Q  = make_model([skewness])\n",
    "D = Q(lam)\n",
    "q_center = Q( lambda_ref )\n",
    "obs_dens_samples_mult = multivariate_normal.rvs(mean=q_center, cov=sigma, size=(1000) )\n",
    "obs_dens_samples_uni = uniform.rvs(loc=q_center-0.5*scale, scale=scale, size=(1000,2) )\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 8, 10\n",
    "plt.cla()\n",
    "plt.title('Data Space with Possible Observed Densities\\nSkewness = %2.2f'%skewness)\n",
    "plt.scatter(D[:,0], D[:,1], label='data')\n",
    "plt.scatter(obs_dens_samples_mult[:,0], obs_dens_samples_mult[:,1], color='r', label='normal, cov=%2.2e'%sigma) \n",
    "plt.scatter(obs_dens_samples_uni[:,0], obs_dens_samples_uni[:,1], color='k', label='uniform, scale=%2.2e'%scale, alpha = 0.035) \n",
    "plt.legend()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the above cell how to compare uniform distributions for our observed density to multivariate normals. \n",
    "\n",
    "For the MS report, a sidelength of $0.1$ was used for the uniform distribution in order to prevent violating the predictability assumption when skewness was equal to 4. Also note that the `loc` parameter passed to `scipy.stats.uniform` needs to be shifted to account for the center, as it is referring to the bottom-left corner instead in $\\mathbb{R}^2$.  \n",
    "\n",
    "With `sigma = 3E-4`, we find that the multivariate normal closely approximates the aforementioned uniform with sidelength $0.1$. Using these, we can safely go up to `skewness=6` before violating the assumption of predictability (dominating measure). \n",
    "\n",
    "Similarly, we can go up to `skew=4` with `cov=1E-3` and `scale=0.2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define QoI\n",
    "The following linear map $Q_s: \\mathbb{R}^2 \\to \\mathbb{R}^2$ is defined to have skewness $s$ at all $\\lambda \\in \\Lambda$.  \n",
    "\n",
    "$$\n",
    "Q_s(\\lambda) = \\lbrace \\, \\lambda_1, \\; \\lambda_1 \\sqrt{s^2 - 1} + \\lambda_2 \\, \\rbrace\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ell_1_error = np.zeros( (skew_range.size, num_samples.size, num_trials) )\n",
    "\n",
    "for s_idx, s in enumerate(skew_range):\n",
    "    print('Skewness = ', s)\n",
    "    lam_emulate = prior_dist( size=(num_emulate, 2) )\n",
    "    Q = make_model([s])\n",
    "    q_emulate = Q( lam_emulate )\n",
    "    pf_dens_reference = gkde(q_emulate) # reference pushforward density\n",
    "    \n",
    "    q_center = Q(lambda_ref)\n",
    "    obs_dens = obs_dens(mean=q_center, cov=sigma) # define the handle, can now call .pdf\n",
    "\n",
    "    for N_idx, N in enumerate(num_samples):\n",
    "        for k in range(num_trials):\n",
    "            print( '(skew, N, k) = (%d, %d, %d)'%(s, n, k) )\n",
    "            lam = prior_dist( size=(n, d) ) # generate some coarse approximations \n",
    "            q = Q( lam )\n",
    "            pf_dens_approx = gkde(q)\n",
    "            \n",
    "            ell_1_error[s_idx, N_idx, k]= ( 1.0/n * np.sum( np.abs(\n",
    "                obs_dens.pdf(q)*(  1/pf_dens.pdf(q) - 1/pf_dens_approx.pdf(q)  ) )) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_idx, s in enumerate(skew_range):\n",
    "    plt.loglog(num_samples, np.mean(ell_1_error[s_idx,:,:],axis=1), label='s=%d'%s)\n",
    "plt.legend(loc=3)\n",
    "\n",
    "plt.savefig('convergence_linearQ_param_skew_vs_samples.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(ell_1_error[0,:,:],axis=1)/np.mean(ell_1_error[2,:,:],axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different vector-valued Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = np.array([1E2, 1E3, 1E4, 1E5]).astype('int')\n",
    "\n",
    "lam_dim = np.array([10])\n",
    "\n",
    "#num_emulate = int(1E5)\n",
    "\n",
    "q_dim = np.array([1, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = pf_dens.interval((0.4))\n",
    "\n",
    "plt.scatter(lam_emulate[:,0], q_emulate[:,0])\n",
    "plt.plot([a, b, b, a, a], [a, a, b, b, a],'r')\n",
    "\n",
    "plt.figure(2)\n",
    "np.count_nonzero(np.where(q_emulate[:,0] < b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = 20\n",
    "\n",
    "ell_1_error = np.zeros((q_dim.size,num_samples.size,repeat))\n",
    "\n",
    "d = lam_dim[0]\n",
    "\n",
    "m_iter = 0\n",
    "for m in q_dim:\n",
    "    print('Dimension = ', m)\n",
    "    pf_dens = chi2(1)\n",
    "    a, b = pf_dens.interval((0.4)**(1/m))\n",
    "    obs_dens = sstats.uniform(a, b)\n",
    "    lam_emulate = np.random.normal(size=(num_emulate,d))\n",
    "    q_emulate = lam_emulate[:,0:m]**2\n",
    "    n_iter = 0\n",
    "    for n in num_samples:\n",
    "        for k in range(repeat):\n",
    "            print('n = ', n)\n",
    "            lam = np.random.normal(size=(n,d))\n",
    "            q = lam[:,0:m]**2\n",
    "            pf_dens_approx = gkde(q.transpose())\n",
    "            #obs_dens_array = np.ones((num_emulate,))\n",
    "            #pf_dens_array = np.ones((num_emulate,))\n",
    "            obs_dens_array = np.ones((n,))\n",
    "            pf_dens_array = np.ones((n,))\n",
    "            for i in range(m):\n",
    "                #obs_dens_array *= obs_dens.pdf(q_emulate[:,i])\n",
    "                #pf_dens_array *= pf_dens.pdf(q_emulate[:,i])\n",
    "                obs_dens_array *= obs_dens.pdf(q[:,i])\n",
    "                pf_dens_array *= pf_dens.pdf(q[:,i])\n",
    "            #ell_1_error[m_iter,n_iter,k]= (1.0/num_emulate * \n",
    "            #                               np.sum(np.abs(obs_dens_array *\n",
    "            #                                    (1/pf_dens_array-\n",
    "            #                                    1/pf_dens_approx.evaluate(q_emulate.transpose())\n",
    "            #                                    )\n",
    "            #                                            )\n",
    "            #                                     )\n",
    "            #                              )\n",
    "            ell_1_error[m_iter,n_iter,k]= (1.0/n * \n",
    "                                           np.sum(np.abs(obs_dens_array *\n",
    "                                                (1/pf_dens_array-\n",
    "                                                1/pf_dens_approx.evaluate(q.transpose())\n",
    "                                                )\n",
    "                                                        )\n",
    "                                                 )\n",
    "                                          )\n",
    "        n_iter +=1\n",
    "    m_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ell_1_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(num_samples, np.mean(ell_1_error[0,:,:],axis=1), label='m=1')\n",
    "plt.loglog(num_samples, np.mean(ell_1_error[1,:,:],axis=1), label='m=2')\n",
    "plt.loglog(num_samples, np.mean(ell_1_error[2,:,:],axis=1), label='m=5')\n",
    "plt.legend(loc=3)\n",
    "\n",
    "plt.savefig('convergence_linearQ_QDim_m_vs_samples.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential inversion -- version 1, separate denominator into product of marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from weighted_kde import gaussian_kde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = multivariate_normal(mean = np.zeros(10), cov = np.eye(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = np.array([1E2, 1E3, 1E4, 1E5]).astype('int')\n",
    "\n",
    "lam_dim = np.array([10])\n",
    "\n",
    "q_dim = np.array([1, 2, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repeat = 20\n",
    "\n",
    "ell_1_error = np.zeros((q_dim.size,num_samples.size,repeat))\n",
    "\n",
    "d = lam_dim[0]\n",
    "\n",
    "m_iter = 0\n",
    "for m in q_dim:\n",
    "    print('Dimension = ', m)\n",
    "    pf_dens = chi2(1)\n",
    "    a, b = pf_dens.interval((0.4)**(1/m))\n",
    "    obs_dens = sstats.uniform(a, b)\n",
    "    n_iter = 0\n",
    "    for n in num_samples:\n",
    "        for k in range(repeat):\n",
    "            print('n = ', n)\n",
    "            lam = np.random.normal(size=(n,d))\n",
    "            obs_dens_array = np.ones((n,))\n",
    "            pf_dens_array = np.ones((n,))\n",
    "            pf_dens_approx_array = np.ones((n,))\n",
    "            #prior_weights = rv.pdf(lam)\n",
    "            for i in range(m):\n",
    "                q = lam[:,i]**2\n",
    "                #if i == 0:\n",
    "                #    pf_dens_approx = gkde(q)\n",
    "                #else:\n",
    "                #    pf_dens_approx = gaussian_kde(q, weights=prior_weights)\n",
    "                pf_dens_approx = gkde(q)\n",
    "                pf_dens_approx_array *= pf_dens_approx.evaluate(q.transpose())\n",
    "                obs_dens_array *= obs_dens.pdf(q)\n",
    "                pf_dens_array *= pf_dens.pdf(q)\n",
    "                #post_weights = prior_weights * obs_dens.pdf(q)/pf_dens_approx.evaluate(q)\n",
    "                #prior_weights = post_weights\n",
    "            ell_1_error[m_iter,n_iter,k]= (1.0/n * \n",
    "                                           np.sum(np.abs(obs_dens_array*(\n",
    "                                               1/pf_dens_array-\n",
    "                                               1/pf_dens_approx_array)\n",
    "                                                         )\n",
    "                                                )\n",
    "                                          )\n",
    "        n_iter +=1\n",
    "    m_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.loglog(num_samples, np.mean(ell_1_error[0,:,:],axis=1), label='m=1')\n",
    "plt.loglog(num_samples, np.mean(ell_1_error[1,:,:],axis=1), label='m=2')\n",
    "plt.loglog(num_samples, np.mean(ell_1_error[2,:,:],axis=1), label='m=5')\n",
    "plt.legend(loc=3)\n",
    "\n",
    "plt.savefig('convergence_linearQ_QDim_m_sequential_vs_samples.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept/reject sampling of posterior if samples come from prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_accept = [lam[:,0]]\n",
    "r = obs_dens.pdf(q)/pf_dens.evaluate(q)\n",
    "M = np.max(r)\n",
    "eta_r = r/M\n",
    "for i in range(num_samples):\n",
    "    xi = np.random.uniform(0,1)\n",
    "    if eta_r[i] > xi:\n",
    "        lam_accept.append(lam[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_accept = np.array(lam_accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lam[0,:],lam[1,:])\n",
    "plt.scatter(lam_accept[:,0],lam_accept[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dens = gkde(lam_accept.transpose()) # Not very useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "plt.plot(x, post_dens.evaluate(pts1),'r')\n",
    "\n",
    "plt.plot(x, prior_dens.pdf(pts1.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dens_TP = gkde(np.sum(lam_accept.transpose(),axis=0)) #Construct the push-forward of the posterior used accepted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,post_dens_TP.evaluate(x)) #Plot the push-forward of the posterior, should look like the observed density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QoI: $q=\\lambda_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = lam[0,:]\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push-forward density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_dens = gkde(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `scipy.stats` to construct observed density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dens = sstats.uniform(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept/reject sampling of posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_accept = [lam[:,0]]\n",
    "r = obs_dens.pdf(q)/pf_dens.evaluate(q)\n",
    "M = np.max(r)\n",
    "eta_r = r/M\n",
    "for i in range(num_samples):\n",
    "    xi = np.random.uniform(0,1)\n",
    "    if eta_r[i] > xi:\n",
    "        lam_accept.append(lam[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_accept = np.array(lam_accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lam[0,:],lam[1,:])\n",
    "plt.scatter(lam_accept[:,0],lam_accept[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltaccept(N):\n",
    "    plt.scatter(lam[0,:],lam[1,:],s=2)\n",
    "    plt.scatter(lam_accept[0:N,0],lam_accept[0:N,1],s=4)\n",
    "\n",
    "num_accept = lam_accept.shape[0]\n",
    "interact(pltaccept, N=(1,num_accept,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dens = gkde(lam_accept.transpose()) #Again, not that useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, post_dens.evaluate(pts1),'r') #Again...not that useful\n",
    "plt.plot(x, prior_dens.pdf(pts1.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dens_TP = gkde(lam_accept[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,post_dens_TP.evaluate(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QoI: $q=\\lambda_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam2 = np.repeat(lam,[100,axis=0)\n",
    "lam2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi_num = 1\n",
    "q = lam[0,:]\n",
    "xi = np.random.randn(int(1E4*xi_num)) * 10\n",
    "q = np.repeat(q,xi_num) + xi\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push-forward density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_dens = gkde(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import `scipy.stats` to construct observed density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_dens = sstats.uniform(0, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept/reject sampling of posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_accept = [lam[:,0]]\n",
    "r = obs_dens.pdf(q)/pf_dens.evaluate(q)\n",
    "M = np.max(r)\n",
    "eta_r = r/M\n",
    "for i in range(num_samples):\n",
    "    eta = np.random.uniform(0,1)\n",
    "    if eta_r[i] > eta:\n",
    "        lam_accept.append(lam[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam_accept = np.array(lam_accept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(lam[0,:],lam[1,:])\n",
    "plt.scatter(lam_accept[:,0],lam_accept[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pltaccept(N):\n",
    "    plt.scatter(lam[0,:],lam[1,:],s=2)\n",
    "    plt.scatter(lam_accept[0:N,0],lam_accept[0:N,1],s=4)\n",
    "\n",
    "num_accept = lam_accept.shape[0]\n",
    "interact(pltaccept, N=(1,num_accept,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dens = gkde(lam_accept.transpose()) #Again, not that useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, post_dens.evaluate(pts1),'r') #Again...not that useful\n",
    "plt.plot(x, prior_dens.pdf(pts1.transpose()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_dens_TP = gkde(lam_accept[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,post_dens_TP.evaluate(x))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
