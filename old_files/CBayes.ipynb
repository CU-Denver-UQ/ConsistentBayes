{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent Bayes: Some Motivating Examples\n",
    "---\n",
    "\n",
    "Copyright 2017-2018 Michael Pilosov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_tested on 3.6 01/23/18_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematics and Plotting\n",
    "from HelperFuns import * # pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "# plt.rcParams['figure.figsize'] = 5, 5\n",
    "from cbayes import sample\n",
    "# from cbayes import \n",
    "# Interactivity\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Some introductory text goes here.   \n",
    "Define $\\Lambda$, $\\mathcal{D}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Sample from $\\Lambda$\n",
    "_Here we implement uniform random priors on the unit hypercube, but you can load in any set of samples in its place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5 # Specify input space dimension (n)\n",
    "num_samples = int(1E4) # number of input samples (N)\n",
    "s_set = sample.sample_set(size=(num_samples, input_dim))\n",
    "s_set.set_dist('uniform')\n",
    "s_set.generate_samples()\n",
    "lam = s_set.samples\n",
    "# lam = np.random.uniform( size = (int(num_samples), int(input_dim)) ) # this would be the equivalent of the object-oriented approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Parameter to Observables (PtO) Map\n",
    "_ Choose from one of the following example options, feel free to add your own _ \n",
    "\n",
    "$O_1(\\lambda) = \\sum_{i=1}^n \\lambda_i$  \n",
    "\n",
    "$O_2(\\lambda) = \\alpha \\, \\lambda_1$, $\\alpha = 2$  \n",
    "\n",
    "$O_3(\\lambda) = \\lbrace \\lambda_0 - \\lambda_1, \\; \\;\\lambda_1\\rbrace$ \n",
    "\n",
    "$O_4(\\lambda) = \\lbrace \\lambda_0+\\lambda_1, \\; \\lambda_2, \\; \\lambda_3-\\lambda_4 \\rbrace$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(lam): # sum all params\n",
    "    return np.array([ np.sum(lam,axis=1) ]).transpose()\n",
    "\n",
    "def fun2(lam): # pull param, scale it.\n",
    "    return np.array([ 2*lam[:,0] ]).transpose()\n",
    "\n",
    "def fun3(lam): # pull two params, linear combination.\n",
    "    return np.array([ lam[:,0] - lam[:,1], lam[:,1] ]).transpose()\n",
    "\n",
    "def fun4(lam): # pull three sets of params, linear combinations thereof.\n",
    "    return np.array([ lam[:,0]+lam[:,1], lam[:,2], lam[:,3]-lam[:,4] ]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PtO_fun_choice = 4\n",
    "\n",
    "if PtO_fun_choice == 1:\n",
    "    PtO_fun = fun1\n",
    "elif PtO_fun_choice == 2:\n",
    "    PtO_fun = fun2\n",
    "elif PtO_fun_choice == 3:\n",
    "    PtO_fun = fun3\n",
    "elif PtO_fun_choice == 4:\n",
    "    PtO_fun = fun4\n",
    "else:\n",
    "    raise( ValueError('Specify Proper PtO choice!') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute Data Space $O(\\Lambda) = \\mathcal{D}$ \n",
    "\n",
    "Format: `(n_dims, n_samples)`  \n",
    "_Optional_: Specify subset of PtO map's components to use for inversion using the variable `sub_indices` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions :  lambda = (10000, 5)   D = (10000, 3)   D_full = (10000, 3)\n"
     ]
    }
   ],
   "source": [
    "p_set = sample.map_samples_and_create_problem(s_set, PtO_fun)\n",
    "D_full = p_set.output.samples\n",
    "# D_full = PtO_fun(lam) # this would be the equivalent of the object-oriented approach\n",
    "sub_indices = None\n",
    "if sub_indices is not None:\n",
    "    D = D_full[:,sub_indices]\n",
    "else:\n",
    "    D = D_full\n",
    "output_dim = D.shape[1]\n",
    "print('dimensions :  lambda = '+str(lam.shape)+'   D = '+str(D.shape)+'   D_full = '+str(D_full.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Push-Forward of the Prior $P_{O(\\Lambda)}$\n",
    "_ ... i.e. Visualize the Data Space_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pf_dens.d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'gkde' object has no attribute 'evaluate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/test_py_env/lib/python3.6/site-packages/ipywidgets-7.1.0-py3.6.egg/ipywidgets/widgets/interaction.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    248\u001b[0m                     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_interact_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwidget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kwarg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0mshow_inline_matplotlib_plots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_display\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/Coding/repositories/ConsistentBayes/old_files/HelperFuns.py\u001b[0m in \u001b[0;36mview_est_dens\u001b[0;34m(x, estimated_dens, viewdim, lab, title)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mviewdim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;31m# specify dim (list) to view crosssections e.g. [0,1] gives you the diagonal view through the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimated_dens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mviewdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'$x_%d$'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mviewdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'gkde' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "# Interactive Marginal Visualization\n",
    "# pf_dens = gkde(D.transpose()) # compute KDE estimate of it\n",
    "p_set.compute_pushforward_dist()\n",
    "pf_dens = p_set.pushforward_dist\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "\n",
    "a, b = -0.25, 1.125 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "widgets.interact(view_est_dens, x = fixed(plot_grid), \n",
    "         estimated_dens = fixed(pf_dens), \n",
    "         lab = fixed('KDE data'), title=fixed('Pushforward of Prior'),\n",
    "         viewdim=(0, output_dim-1, 1) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Observed Probability Measure $P_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use multivariate normals because of their common scipy.stats call syntaxes.\n",
    "var_const = 0.1 # constant variance for simplicity\n",
    "cov_matrix = var_const*np.eye(output_dim) # if you want non-constant, use code snippet below\n",
    "# cov_matrix = np.diag( np.round(np.random.rand(1,output_dim),2)[0] ) # random independent covariances\n",
    "means = np.zeros(output_dim) + 0.5 # observed density center (maximum)\n",
    "obs_dens = sstats.multivariate_normal(mean = means, cov = cov_matrix )\n",
    "\n",
    "# # For the 1-dimensional case, we can utilize the uniform density given below\n",
    "# # TODO: generalize uniform box to n-dimensional case\n",
    "# uni_max = 0.5\n",
    "# obs_dens = sstats.uniform(0,uni_max) # 1D only\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "interact(view_analytical_dens, x = fixed(plot_grid), \n",
    "         analytical_dens = fixed(obs_dens), \n",
    "         lab = fixed('KDE data'), title=fixed('Observed $P_\\mathcal{D}$'),\n",
    "         viewdim=(0, output_dim-1, 1) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point we have performed the computations we need to. We have evaluated the input points through our map and performed a KDE on them. It would be useful at this point to save this object and/or its evaluation at every point in the data space for later re-use. Doing so here would be an appropriate place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Accept/Reject Sampling of Posterior\n",
    "\n",
    "Since we have already used the samples in our prior to compute the pushforward density, we can re-use these with an accept/reject algorithm to get a set of samples generated from the posterior according to the solution of the stochastic inverse problem as outlined in the Consistent Bayes formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = []\n",
    "# the transpose below is how analytical densities take their arguments. KDE objects do not require transpose.\n",
    "r = obs_dens.pdf( D.transpose() ) / pf_dens.evaluate(D) # vector of ratios evaluated at all the O(lambda)'s\n",
    "M = np.max(r)\n",
    "eta_r = r/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = [i for i in range(num_samples) if eta_r[i] > np.random.uniform(0,1) ]\n",
    "lam_accept = np.array([lam[i,accept_inds] for i in range(input_dim)])\n",
    "num_accept = len(accept_inds)\n",
    "print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Accept/Reject Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "interact(pltaccept, lam = fixed(lam), lam_accept = fixed(lam_accept), \n",
    "         N = (1, num_accept+1, 10), eta_r = fixed(eta_r), \n",
    "         i = (0, input_dim-1, 1), j = (0, input_dim-1, 1))\n",
    "# You will visualize the accepted samples in a subset of size N of the input samples\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Visualize Posterior Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dens_kde = gkde(lam)\n",
    "post_dens_kde = gkde(lam_accept)\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "interact(compare_est_input_dens, x = fixed(plot_grid), \n",
    "         estimated_dens1 = fixed(prior_dens_kde), estimated_dens2 = fixed(post_dens_kde), \n",
    "         lab_1 = fixed('KDE prior'), lab_2 = fixed('KDE post'), title=fixed(''),\n",
    "         viewdim=(0, input_dim-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Quality of Solution \n",
    "_We compare the push-forward of the posterior using accepted samples against the observed density_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_post_dens_kde = gkde([D[k][accept_inds] for k in range(output_dim)])\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "\n",
    "# diagonal crossection view\n",
    "interact(compare_output_dens, x = fixed(plot_grid), \n",
    "         analytical_dens = fixed(obs_dens), estimated_dens = fixed(push_post_dens_kde), \n",
    "         lab_1 = fixed('observed'), lab_2 = fixed('KDE push'), title = fixed('Marginal - Observed v. PF'),\n",
    "         viewdim = (0, output_dim-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "test_py_env",
   "language": "python",
   "name": "test_py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
