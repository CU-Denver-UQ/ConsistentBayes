{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent Bayes: Examples from the Paper\n",
    "---\n",
    "\n",
    "Copyright 2018 Michael Pilosov\n",
    "\n",
    "Based on work done by ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_tested with python 3.6 on 02/11/18_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mathematics and Plotting\n",
    "from HelperFuns import * # pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\n",
    "# %matplotlib inline\n",
    "# %matplotlib notebook\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['figure.figsize'] = 8, 5\n",
    "from cbayes import sample, solve, distributions\n",
    "# Interactivity\n",
    "from ipywidgets import *\n",
    "\n",
    "# import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "# import matplotlib.pyplot as plt\n",
    "import progressbar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Summary\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### FIXED PARAMETERS #####\n",
    "\n",
    "num_observations = 52 # how many observations are you able to make over the year?\n",
    "assumed_population_size = 1E5 # your assumed population size (truth for the model)\n",
    "infection_rate = 0.2 # (ppl/day) assumed infection rate\n",
    "recovery_time = 10 # (1/days) assumed recovery rate. both of these shouldn't matter if we do a good job ID'ing them.\n",
    "####\n",
    "\n",
    "def SSE_generator(model, obs_data, sigma=1):   # this generates a sum of squared residuals.\n",
    "    def QoI_fun(inputs):         # that conforms to our desired model input\n",
    "        predictions = model(inputs)\n",
    "        assert predictions.shape[1] == len(obs_data)\n",
    "        residuals = predictions - obs_data\n",
    "        QoI = np.sum( (residuals/sigma)**2, axis=1 )\n",
    "        return QoI\n",
    "    return QoI_fun\n",
    "\n",
    "# The SIR model differential equations.\n",
    "def deriv(y, t, beta, gamma):\n",
    "    S, I, R = y\n",
    "    dSdt = -beta * S * I \n",
    "    dIdt = beta * S * I - gamma * I\n",
    "    dRdt = gamma * I\n",
    "    return dSdt, dIdt, dRdt\n",
    "\n",
    "def SIR(beta=infection_rate, gamma = 1./recovery_time, I0=1./assumed_population_size, t=np.linspace(0,365,52),verbose=False):\n",
    "    # I0 is number of initial infected individuals\n",
    "    # R0 is number of initial  recovered/immune individuals\n",
    "    # S0 is everyone else, the susceptible \n",
    "    # beta is contact rate (socialness of society) (ppl/day)\n",
    "    # gamma is recovery rate (days^-1)\n",
    "    R0 = 0 # WE ALSO ASSUME ZERO NATURAL IMMUNITY OR VACCINE\n",
    "    S0 = 1. - R0 - I0\n",
    "    try:\n",
    "        assert(S0+I0+R0 == 1)\n",
    "    except AssertionError:\n",
    "        print(\"R0 must be nonnegative. you passed infeasible parameters\")\n",
    "        pass\n",
    "    y0 = np.array([S0, I0, R0])     # Initial conditions vector\n",
    "    if verbose:\n",
    "        print(\"[b, g] = [%.2f, %.2f], [S0 I0 R0] = [%.2f, %1.2e, %1.2e]\"%(beta, gamma, y0[0], y0[1], y0[2]), \"| max time =\", t[-1], \"| h =\", len(t))\n",
    "    ret = odeint(deriv, y0, t, args=(beta, gamma))\n",
    "    S, I, R = ret.T # Integrate the SIR equations over the time grid, t.\n",
    "    return S, I, R\n",
    "\n",
    "\n",
    "# This is for when we collect 2-D data\n",
    "def epidemic_IR(lam, verbose=False):\n",
    "    num_samples = lam.shape[0]\n",
    "    days = 365\n",
    "    h = num_observations\n",
    "    t = np.linspace(0, days, h)\n",
    "    I_out = np.empty(shape=(num_samples, h))\n",
    "    R_out = np.empty(shape=(num_samples, h))\n",
    "    bar = progressbar.ProgressBar()\n",
    "    for n in bar(range(num_samples)):\n",
    "        beta, gamma, S0 = lam[n,:]\n",
    "        S, I, R = SIR(beta, gamma, S0, t, verbose=verbose)\n",
    "        I_out[n,:] = I\n",
    "        R_out[n,:] = R\n",
    "    return np.array([I_out, R_out])\n",
    "\n",
    "\n",
    "def epidemic_I(lam, verbose=False): # necessary wrapper functions for SSE_generator\n",
    "    I_out, R_out = epidemic_IR(lam,verbose)\n",
    "    return I_out\n",
    "\n",
    "def epidemic_R(lam, verbose=False):\n",
    "    I_out, R_out = epidemic_IR(lam,verbose)\n",
    "    return R_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0, 365, num_observations)\n",
    "S,I,R = SIR(t=t,verbose=True)\n",
    "# Plot the data on three separate curves for S(t), I(t) and R(t)\n",
    "fig = plt.figure(facecolor='w')\n",
    "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
    "ax.plot(t, S, 'b', alpha=0.5, lw=2, label='Susceptible')\n",
    "ax.plot(t, I, 'r', alpha=0.5, lw=2, label='Infected')\n",
    "ax.plot(t, R, 'g', alpha=0.5, lw=2, label='Recovered with immunity')\n",
    "\n",
    "ax.set_xlabel('Time (days)')\n",
    "ax.set_ylabel('Proportion of Population')\n",
    "\n",
    "ax.set_ylim(0,1.2)\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "\n",
    "ax.grid(b=True, which='major', c='w', lw=2, ls='-')\n",
    "legend = ax.legend()\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "for spine in ('top', 'right', 'bottom', 'left'):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a sense of the variation \n",
    "\n",
    "A common parameter choice is $\\beta$ = 0.2 and $\\gamma$ = 0.1, let us see how much varation this leads to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(1E1)\n",
    "beta = 0.2\n",
    "gamma = 0.1\n",
    "num_days = 365\n",
    "lam = np.zeros((n,3))\n",
    "lam[:,0] = beta\n",
    "lam[:,1] = gamma\n",
    "lam[:,2] = 1./np.linspace(1E3, 1E6, n)# I0\n",
    "data = epidemic_IR(lam,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the default IR results from the epidemic_IR function.\n",
    "t = np.linspace(0,num_days,num_observations) # time vector\n",
    "for i in range(n):\n",
    "    plt.plot(t, data[0, i, :]) # I\n",
    "    plt.plot(t, data[1, i, :]) # R\n",
    "#     plt.plot(t, 1 - data[0, i, :] - data[1, i, :])\n",
    "plt.plot(t,I,c='k')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Define Your Parameter-to-Observables Map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observables = 1 # are you observing I (num_obs = 1) or both I and R (num_obs = 2)\n",
    "output_dim = 1 # are you assimilating the data into a 1D or 2D vector?\n",
    "sd_R = 0.1/6\n",
    "sd_I = np.sqrt(1/6)\n",
    "\n",
    "S_t, I_t, R_t = SIR() # t as a subscript stands for \"truth\"\n",
    "obs_data_I = I_t + np.random.randn(int(num_observations))*sd_I\n",
    "obs_data_R = R_t + np.random.randn(int(num_observations))*sd_R\n",
    "\n",
    "# if observables == 2:\n",
    "#     if output_dim == 1: # concatenate the Chi^2 data.\n",
    "#         PtO_fun = SSE_generator(epidemic_I, obs_data_I, sd_I) + SE_generator(epidemic_R, obs_data_R, sd_R)\n",
    "#         # I REALLYYYYY HOPE THIS WORKS\n",
    "#     else: # output_dim = 2, treat as dual-Chi^2\n",
    "#         PtO_fun = np.array([SSE_generator(epidemic_I, obs_data_I, sd_I), SE_generator(epidemic_R, obs_data_R, sd_R)])\n",
    "# else: # one observable\n",
    "PtO_fun = SSE_generator(epidemic_I, obs_data_I, sd_I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Define Prior Measure $P_\\Lambda$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 3 # Specify input space dimension (n)\n",
    "num_samples = int(1E4) # number of input samples (N)\n",
    "s_set = sample.sample_set(size=(num_samples, input_dim))\n",
    "min_population_size = 100 # that you are willing to consider.\n",
    "max_population_size = 1E6 # that you are willing to consider.\n",
    "\n",
    "s_set.set_dist('beta', kwds={'a': 1, 'b': 1, 'loc': 0, 'scale': 1}, dim=0) # beta - rate of (ppl/day)\n",
    "s_set.set_dist('beta', kwds={'a': 1, 'b': 1, 'loc': 0, 'scale': 1}, dim=1) # gamma - recovery rate (1/days)\n",
    "s_set.set_dist('beta', kwds={'a': 1, 'b': 1, 'loc': 1./min_population_size, 'scale': 1./min_population_size - 1./max_population_size}, dim=2) # I_0 (1/population_size)\n",
    "s_set.generate_samples()\n",
    "\n",
    "lam = s_set.samples # create a pointer for ease of reference later with plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prior "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(lam), inds = fixed(None), \n",
    "                    N = widgets.IntSlider(value=500, min = 100, max=5000, step=100, continuous_update=False), \n",
    "                    eta_r = fixed(None), space=fixed(0.05), svd=widgets.Checkbox(value=False), color=widgets.Text(value=\"orange\", continuous_update=False),\n",
    "                    view_dim_1 = widgets.IntSlider(value=0, min=0, max=input_dim-1, step=1, continuous_update=False), \n",
    "                    view_dim_2 = widgets.IntSlider(value=input_dim-1, min=0, max=input_dim-1, step=1, continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Compute Data Space $O(\\Lambda) = \\mathcal{D}$ \n",
    "\n",
    "Format: `(n_dims, n_samples)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set = sample.map_samples_and_create_problem(s_set, PtO_fun)\n",
    "D = p_set.output.samples\n",
    "\n",
    "# This is how we handle trying to infer the dimension based on what the map put out.\n",
    "# You can delete this once you are certain your model is correctly defined.\n",
    "try:\n",
    "    output_dim = D.shape[1] # if your function was coded correctly, you should have an (n, d) data space.\n",
    "except IndexError:\n",
    "    print(Warning(\"Warning: Your map might be returning the wrong dimensional data.\"))\n",
    "    try:\n",
    "       output_dim = D.shape[0] \n",
    "    except IndexError:\n",
    "        print(Warning(\"Warning: Guessing it's 1-dimensional.\"))\n",
    "        output_dim = 1\n",
    "print('dimensions :  lambda = '+str(lam.shape)+'   D = '+str(D.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Push-Forward of the Prior $P_{O(\\Lambda)}$\n",
    "_ ... i.e. Characterize the Data Space_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Interactive Marginal Visualization\n",
    "p_set.compute_pushforward_dist()\n",
    "pf_dist = p_set.pushforward_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pf_dist.kde_object.set_bandwidth(1E-10)\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(pf_dist), inds = fixed(None), \n",
    "        N = widgets.IntSlider(value=10000, min = 100, max=10000, step=100, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=fixed(False), color=widgets.Text(value=\"brown\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=output_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=output_dim-1, min=0, max=output_dim-1, step=1, continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Observed Probability Measure $P_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if observables == 1: # you get to observe I\n",
    "    p_set.set_observed_dist('chi2', {'df':num_observations}, dim=0)\n",
    "else: # you get to observe R as well\n",
    "    if output_dim == 1:\n",
    "        p_set.set_observed_dist('chi2', {'df':2*num_observations}, dim=0)\n",
    "    else:\n",
    "        p_set.set_observed_dist('chi2', {'df':num_observations}, dim=0)\n",
    "        p_set.set_observed_dist('chi2', {'df':num_observations}, dim=1)\n",
    "\n",
    "obs_dist = p_set.observed_dist # this is define a pointer for ease of reference.\n",
    "\n",
    "widgets.interactive(pltdata, data = fixed(obs_dist), inds = fixed(None), \n",
    "        N = widgets.IntSlider(value=500, min = 100, max=5000, step=100, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=fixed(False), color=widgets.Text(value=\"wine\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=output_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=output_dim-1, min=0, max=output_dim-1, step=1, continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point we have performed the computations we need to. We have evaluated the input points through our map and performed a KDE on them. It would be useful at this point to save this object and/or its evaluation at every point in the data space for later re-use. Doing so here would be an appropriate place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "# Accept/Reject Sampling of Posterior\n",
    "\n",
    "Since we have already used the samples in our prior to compute the pushforward density, we can re-use these with an accept/reject algorithm to get a set of samples generated from the posterior according to the solution of the stochastic inverse problem as outlined in the Consistent Bayes formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_set.set_ratio()\n",
    "eta_r = p_set.ratio\n",
    "solve.problem(p_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = p_set.accept_inds\n",
    "lam_accept = p_set.input.samples[accept_inds,:]\n",
    "num_accept = len(accept_inds)\n",
    "print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Posterior Density\n",
    "### (Visualize Accept/Reject Samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(lam), inds = fixed(accept_inds), \n",
    "        N = widgets.IntSlider(value=num_accept/2, min = 2, max=num_accept+1, step=1, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=widgets.Checkbox(value=False), color=widgets.Text(value=\"orange\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=input_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=input_dim-1, min=0, max=input_dim-1, step=1, continuous_update=False))\n",
    "\n",
    "# You will visualize the accepted samples in a subset of size N of the input samples. \n",
    "# This is mostly for faster plotting, but also so you can see the progression of accepted sampling in the algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Now what? \n",
    "\n",
    "Well, we can...\n",
    "\n",
    "## _Visualize the Quality of our SIP Solution by Comparing it to the Observed_\n",
    "_We compare the push-forward of the posterior using accepted samples against the observed density_  \n",
    "_(SIP = Stochastic Inverse Problem)_\n",
    "### Observed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(obs_dist), inds = fixed(None), \n",
    "        N = widgets.IntSlider(value=500, min = 100, max=5000, step=100, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=fixed(False), color=widgets.Text(value=\"wine\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=output_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=output_dim-1, min=0, max=output_dim-1, step=1, continuous_update=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushforward of Posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interactive(pltdata, data = fixed(D), inds = fixed(accept_inds), \n",
    "        N = widgets.IntSlider(value=num_accept/2, min = 2, max=num_accept-1, step=1, continuous_update=False), \n",
    "        eta_r = fixed(None), space=fixed(0.05), svd=fixed(False), color=widgets.Text(value=\"eggplant\", continuous_update=False),\n",
    "        view_dim_1 = widgets.IntSlider(value=0, min=0, max=output_dim-1, step=1, continuous_update=False), \n",
    "        view_dim_2 = widgets.IntSlider(value=output_dim-1, min=0, max=output_dim-1, step=1, continuous_update=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify our parametric test statistics.\n",
    "Let's see if the pushforward of the posterior results in a sample mean and standard deviation that are close to the observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[np.mean(D[accept_inds,:]), np.std(D[accept_inds,:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[p_set.observed_dist.mean(), p_set.observed_dist.std()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look pretty good! Now go back to the [Sampling Section](#Sample-from-Prior) and change the distribution on the prior or choose another example problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "test_py_env",
   "language": "python",
   "name": "test_py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
