{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent Bayes: Some Motivating Examples\n",
    "---\n",
    "\n",
    "Copyright 2017-2018 Michael Pilosov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_tested on 3.6 01/23/18_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CBayes.ipynb\r\n",
      "Example_How_to_Parallelize_Code.ipynb\r\n",
      "Example_MS_Troy_dimension_depency.ipynb\r\n",
      "consistentbayes_example.py\r\n",
      "problem_solve.py\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'HelperFuns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-75cf9325ceb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mathematics and Plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mHelperFuns\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;31m# pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'font.size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'HelperFuns'"
     ]
    }
   ],
   "source": [
    "# Mathematics and Plotting\n",
    "from HelperFuns import * # pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "from cbayes import sample, solve\n",
    "# Interactivity\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Some introductory text goes here.   \n",
    "Define $\\Lambda$, $\\mathcal{D}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Sample from $\\Lambda$\n",
    "_Here we implement uniform random priors on the unit hypercube, but you can load in any set of samples in its place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2 # Specify input space dimension (n)\n",
    "num_samples = int(1E4) # number of input samples (N)\n",
    "s_set = sample.sample_set(size=(num_samples, input_dim))\n",
    "s_set.set_dist('uniform')\n",
    "s_set.generate_samples()\n",
    "lam = s_set.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Parameter to Observables (PtO) Map\n",
    "_ Choose from one of the following example options, feel free to add your own _ \n",
    "\n",
    "$O_1(\\lambda) = \\sum_{i=1}^n \\lambda_i$  \n",
    "\n",
    "$O_2(\\lambda) = \\alpha \\, \\lambda_1$, $\\alpha = 2$  \n",
    "\n",
    "$O_3(\\lambda) = \\lbrace \\lambda_0 - \\lambda_1, \\; \\;\\lambda_1\\rbrace$ \n",
    "\n",
    "$O_4(\\lambda) = \\lbrace \\lambda_0+\\lambda_1, \\; \\lambda_2, \\; \\lambda_3-\\lambda_4 \\rbrace$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(lam): # sum all params\n",
    "    return np.sum(lam,axis=1)\n",
    "\n",
    "def fun2(lam): # pull param, scale it.\n",
    "    return np.array([ 2*lam[:,0] ]).transpose()\n",
    "\n",
    "def fun3(lam): # pull two params, linear combination.\n",
    "    return np.array([ lam[:,0] - lam[:,1], lam[:,1] ]).transpose()\n",
    "\n",
    "def fun4(lam): # pull three sets of params, linear combinations thereof.\n",
    "    return np.array([ lam[:,0]+lam[:,1], lam[:,2], lam[:,3]-lam[:,4] ]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PtO_fun_choice = 1\n",
    "\n",
    "if PtO_fun_choice == 1:\n",
    "    PtO_fun = fun1\n",
    "elif PtO_fun_choice == 2:\n",
    "    PtO_fun = fun2\n",
    "elif PtO_fun_choice == 3:\n",
    "    PtO_fun = fun3\n",
    "elif PtO_fun_choice == 4:\n",
    "    PtO_fun = fun4\n",
    "else:\n",
    "    raise( ValueError('Specify Proper PtO choice!') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute Data Space $O(\\Lambda) = \\mathcal{D}$ \n",
    "\n",
    "Format: `(n_dims, n_samples)`  \n",
    "_Optional_: Specify subset of PtO map's components to use for inversion using the variable `sub_indices` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set = sample.map_samples_and_create_problem(s_set, PtO_fun)\n",
    "D_full = p_set.output.samples\n",
    "\n",
    "sub_indices = None\n",
    "if sub_indices is not None:\n",
    "    D = D_full[:,sub_indices]\n",
    "else:\n",
    "    D = D_full\n",
    "    type(np.sum(lam, axis=1))\n",
    "# this is how we handle exceptions:\n",
    "try:\n",
    "    output_dim = D.shape[1]\n",
    "except IndexError:\n",
    "    output_dim = 1\n",
    "print('dimensions :  lambda = '+str(lam.shape)+'   D = '+str(D.shape)+'   D_full = '+str(D_full.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Push-Forward of the Prior $P_{O(\\Lambda)}$\n",
    "_ ... i.e. Visualize the Data Space_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Interactive Marginal Visualization\n",
    "p_set.compute_pushforward_dist()\n",
    "pf_dens = p_set.pushforward_dist\n",
    "\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "\n",
    "a, b = -0.25, 2.125 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "widgets.interact(view_est_dens, x = fixed(plot_grid), \n",
    "         estimated_dens = fixed(pf_dens), \n",
    "         lab = fixed('KDE data'), title=fixed('Pushforward of Prior'),\n",
    "         viewdim=(0, output_dim-1, 1) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Observed Probability Measure $P_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use multivariate normals because of their common scipy.stats call syntaxes.\n",
    "var_const = 0.25 # constant variance for simplicity\n",
    "cov_matrix = var_const*np.eye(output_dim) # if you want non-constant, use code snippet below\n",
    "# cov_matrix = np.diag( np.round(np.random.rand(1,output_dim),2)[0] ) # random independent covariances\n",
    "means = np.zeros(output_dim) + 0.875 # observed density center (maximum)\n",
    "# obs_dens = sstats.multivariate_normal(mean = means, cov = cov_matrix )\n",
    "p_set.set_observed_dist('uniform', means, var_const)\n",
    "obs_dens = p_set.observed_dist\n",
    "\n",
    "# # For the 1-dimensional case, we can utilize the uniform density given below\n",
    "# # TODO: generalize uniform box to n-dimensional case\n",
    "# uni_max = 0.5\n",
    "# obs_dens = sstats.uniform(0,uni_max) # 1D only\n",
    "\n",
    "# a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "widgets.interact(view_analytical_dens, x = fixed(plot_grid), \n",
    "         analytical_dens = fixed(obs_dens), \n",
    "         lab = fixed('KDE data'), title=fixed('Observed $P_\\mathcal{D}$'),\n",
    "         viewdim=(0, output_dim-1, 1) )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point we have performed the computations we need to. We have evaluated the input points through our map and performed a KDE on them. It would be useful at this point to save this object and/or its evaluation at every point in the data space for later re-use. Doing so here would be an appropriate place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Accept/Reject Sampling of Posterior\n",
    "\n",
    "Since we have already used the samples in our prior to compute the pushforward density, we can re-use these with an accept/reject algorithm to get a set of samples generated from the posterior according to the solution of the stochastic inverse problem as outlined in the Consistent Bayes formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_set.set_ratio()\n",
    "eta_r = p_set.ratio\n",
    "solve.problem(p_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = p_set.accept_inds\n",
    "lam_accept = p_set.input.samples[accept_inds,:]\n",
    "num_accept = len(accept_inds)\n",
    "print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Accept/Reject Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(pltaccept, lam = fixed(lam), inds = fixed(accept_inds), \n",
    "         N = (1, num_accept+1, 10), eta_r = fixed(eta_r), \n",
    "         i = (0, input_dim-1, 1), j = (0, input_dim-1, 1))\n",
    "# You will visualize the accepted samples in a subset of size N of the input samples\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Visualize Posterior Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dens_kde = gauss_kde(lam.transpose()) # this method wants dimensions different than ours.\n",
    "post_dens_kde = gauss_kde(lam_accept.transpose())\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "interact(compare_est_input_dens, x = fixed(plot_grid), \n",
    "         estimated_dens1 = fixed(prior_dens_kde), estimated_dens2 = fixed(post_dens_kde), \n",
    "         lab_1 = fixed('KDE prior'), lab_2 = fixed('KDE post'), title=fixed(''),\n",
    "         viewdim=(0, input_dim-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Quality of Solution \n",
    "_We compare the push-forward of the posterior using accepted samples against the observed density_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D[accept_inds,:].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_post_dens_kde = gauss_kde(D[accept_inds,:].transpose())\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "\n",
    "# diagonal crossection view\n",
    "interact(compare_output_dens, x = fixed(plot_grid), \n",
    "         analytical_dens = fixed(obs_dens), estimated_dens = fixed(push_post_dens_kde), \n",
    "         lab_1 = fixed('observed'), lab_2 = fixed('KDE push'), title = fixed('Marginal - Observed v. PF'),\n",
    "         viewdim = (0, output_dim-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "test_py_env",
   "language": "python",
   "name": "test_py_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
