{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent Bayes: Some Motivating Examples\n",
    "---\n",
    "\n",
    "Author: Michael Pilosov\n",
    "Copyright 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_(should be 2.7 and 3.x compatible) _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mathematics and Plotting\n",
    "from HelperFuns import * # pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "# Interactivity\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Some introductory text goes here.   \n",
    "Define $\\Lambda$, $\\mathcal{D}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Sample from $\\Lambda$\n",
    "_Here we implement uniform random priors on the unit hypercube, but you can load in any set of samples in its place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 1 # Specify input space dimension (n)\n",
    "num_samples = int(1E4) # number of input samples (N)\n",
    "lam = np.random.uniform( size = (input_dim, num_samples) ) # generate samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Parameter to Observables (PtO) Map\n",
    "_ Choose from one of the following example options, feel free to add your own _ \n",
    "\n",
    "$O_1(\\lambda) = (\\lambda_1-\\frac{1}{2})^2$  \n",
    "\n",
    "$O_2(\\lambda) = \\sum_{i=1}^n \\lambda_i$  \n",
    "\n",
    "$O_3(\\lambda) = \\lbrace \\lambda_0, \\; \\lambda_3 \\rbrace$ \n",
    "\n",
    "$O_4(\\lambda) = \\lbrace \\lambda_0+\\lambda_1, \\; \\lambda_2, \\; \\lambda_3-\\lambda_4 \\rbrace$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PtO_fun1(lam): # pull first element\n",
    "    return np.array([ (lam[0,:] - 0.5)**2 ])\n",
    "\n",
    "def PtO_fun2(lam): # sum all elements\n",
    "    return np.array([ np.sum(lam,axis=0) ])\n",
    "\n",
    "def PtO_fun3(lam): # pull two elements\n",
    "    return np.array([ lam[0,:], lam[3,:] ])\n",
    "\n",
    "def PtO_fun4(lam): # three elements\n",
    "    return np.array([ lam[0,:]+lam[1,:], lam[2,:], lam[3,:]-lam[4,:] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PtO_fun_choice = 1\n",
    "\n",
    "if PtO_fun_choice == 1:\n",
    "    PtO_fun = PtO_fun1\n",
    "elif PtO_fun_choice == 2:\n",
    "    PtO_fun = PtO_fun2\n",
    "elif PtO_fun_choice == 3:\n",
    "    PtO_fun = PtO_fun3\n",
    "elif PtO_fun_choice == 4:\n",
    "    PtO_fun = PtO_fun4\n",
    "else:\n",
    "    raise( ValueError('Specify Proper PtO choice!') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute Data Space $O(\\Lambda) = \\mathcal{D}$ \n",
    "\n",
    "Format: `(n_dims, n_samples)`  \n",
    "_Optional_: Specify subset of PtO map's components to use for inversion using the variable `sub_indices` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions :  lambda = (1, 10000)   D = (1, 10000)   D_full = (1, 10000)\n"
     ]
    }
   ],
   "source": [
    "D_full = PtO_fun(lam)\n",
    "sub_indices = None\n",
    "if sub_indices is not None:\n",
    "    D = D_full[sub_indices,:]\n",
    "else:\n",
    "    D = D_full\n",
    "output_dim = D.shape[0]\n",
    "print('dimensions :  lambda = '+str(lam.shape)+'   D = '+str(D.shape)+'   D_full = '+str(D_full.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f4236933034c3c8bc8d5e4b04557b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function HelperFuns.view_est_dens>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Below you will find one-dimensional histogram option\n",
    "# M = 100 # number of bins in the data space\n",
    "# plt.hist(D[0],M)\n",
    "# plt.title('histogram of data space')\n",
    "# plt.show()\n",
    "\n",
    "# Interactive Marginal Visualization\n",
    "data_space_kde = gkde(D[0]) # compute KDE estimate of it\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "a, b = 0, 0.25 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "interact(view_est_dens, x = fixed(plot_grid), \n",
    "         estimated_dens = fixed(data_space_kde), \n",
    "         lab = fixed('KDE data'), title=fixed('Marginal (est.) of $\\mathcal{D}$'),\n",
    "         viewdim=(0, input_dim-1, 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Observed Probability Measure $P_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# var_const = .1\n",
    "\n",
    "# Interesting things happen with time series data that uses uniform on output.\n",
    "uni_max = 0.5\n",
    "obs_dens = sstats.uniform(0,uni_max) # 1D only\n",
    "# obs_dens = sstats.norm(0.5,sigma) # 1D only\n",
    "# But if the errors are normally distributed, the observed density will by a chi^2 of order K.\n",
    "# print num_times\n",
    "# obs_dens = sstats.chi2(num_times)\n",
    "xx = np.linspace(-1,1,100)\n",
    "plt.plot(xx,obs_dens.pdf(xx)) # CHI SQUARED\n",
    "# plt.plot(xx,np.divide(1,obs_dens.pdf(xx))) # RECIPRICAL CHI SQUARED\n",
    "\n",
    "# TODO: add support for multivariate uniforms. \n",
    "\n",
    "# obs_dens = sstats.multivariate_normal(mean = np.zeros(output_dim), \n",
    "#                                       cov = var_const*np.eye(output_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for d_dim in range(1,21):\n",
    "#     d = sstats.multivariate_normal(mean = np.zeros(d_dim), cov = np.eye(d_dim))\n",
    "#     print '%2.2e'%d.pdf(np.zeros(d_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.max(q[0])\n",
    "# num_times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute push-forward of the prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pf_dens = gkde(q[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0,1.1*np.max(q[0]),100)\n",
    "plt.plot(x,pf_dens.evaluate(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accept/reject sampling of posterior\n",
    "(samples come from prior that was used to compute the pushforward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam_accept = []\n",
    "# r = (1./obs_dens.pdf( q )) / pf_dens.evaluate(q) # RECIPRICAL CHI SQUARED. REGULAR IS BELOW.\n",
    "r = obs_dens.pdf( q ) / pf_dens.evaluate(q) # vector of ratios evaluated at all the q(lambda)'s\n",
    "M = np.max(r)\n",
    "eta_r = r[0]/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    xi = np.random.uniform(0,1)\n",
    "    if eta_r[i] > xi:\n",
    "        lam_accept.append( lam[:,i] )\n",
    "\n",
    "lam_accept = np.array( lam_accept[1::] ).transpose()\n",
    "num_accept = lam_accept.shape[1]\n",
    "print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.sum(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(lam,eta_r)\n",
    "# plt.scatter([lam0],0.05)\n",
    "# plt.xlim([0.05-0.01, 0.05+0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# interact(pltaccept, lam = fixed(lam), lam_accept = fixed(lam_accept), \n",
    "#          N = (1, num_accept, 10), i = (0, input_dim-1, 1), j = (0, input_dim-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = int(1E4)\n",
    "num_times = 1000 # measurement frequency (K)\n",
    "# number of model solves = num_samples*num_times. dim_qoi = 1 because we are assimilating measurements into a single QoI\n",
    "T_min, T_max = 0.1, 10 #  max time\n",
    "# uni_max = 1E-3\n",
    "lam0 = 1 # true / reference lambda_0\n",
    "sd = 0.2 # STANDARD DEVIATION FOR EACH MEASUREMENT. this makes it constant for all of them.\n",
    "\n",
    "############################\n",
    "input_dim = 1\n",
    "lam = 2*np.random.uniform( size = (input_dim, num_samples) ) # standard uniform PRIOR\n",
    "x = np.linspace(0, 2, 100) # for plotting purposes\n",
    "\n",
    "sigma = sd*np.ones(num_times+1)\n",
    "t = np.linspace(T_min,T_max,num_times) # INCLUDES T_min - Useful if you want to be very specific about start-time\n",
    "# t = np.linspace(T_min,T_max,num_times+1)[1::] # EXCLUDES T_min - Useful if you want to keep T_min at 0\n",
    "# print t\n",
    "def data(lam):\n",
    "    noise = 1 # noise on or off\n",
    "    return lam0*np.exp(-t) + noise*sd*np.random.randn(1,num_times)\n",
    "d = data(lam) # make random data. fix it.\n",
    "\n",
    "def QoI_fun(d,lam):\n",
    "    noise = 0 # stochastic map or no? treating model like best unbiased predictor\n",
    "    return (1./1)*np.sum([np.power([ ( lam*np.exp(-t[k]) + noise*sd*np.random.randn(1,num_samples)\n",
    "                                      - d[0,k])/sigma[k] ],2)[0] for k in range(num_times)],0)\n",
    "\n",
    "print('Computing QoI')\n",
    "q_full = QoI_fun(d,lam)\n",
    "QoI_indices = None\n",
    "if QoI_indices is not None:\n",
    "    q = q_full[QoI_indices,:]\n",
    "else:\n",
    "    q = q_full\n",
    "        \n",
    "print('Summary of dimensions :  lambda = '+str(lam.shape)+'   q = '+str(q.shape)+'   q_full = '+str(q_full.shape) )\n",
    "print('Defining Observed Density with bound %2.2e'%(uni_max))\n",
    "# obs_dens = sstats.uniform(0,uni_max) # 1D only\n",
    "obs_dens = sstats.chi2(num_times)\n",
    "\n",
    "pf_dens = gkde(q[0])\n",
    "lam_accept = []\n",
    "# r = (1./obs_dens.pdf( q )) / pf_dens.evaluate(q) # RECIPRICAL CHI SQUARED. REGULAR IS BELOW.\n",
    "print('Computing weights')\n",
    "r = obs_dens.pdf( q ) / pf_dens.evaluate(q) # vector of ratios evaluated at all the q(lambda)'s\n",
    "M = np.max(r)\n",
    "eta_r = r[0]\n",
    "inds = []\n",
    "##### OPTIONAL - RUN ACCEPT/REJECT\n",
    "# print('Performing accept/reject')\n",
    "# for i in range(num_samples):\n",
    "#     xi = np.random.uniform(0,1)\n",
    "#     if eta_r[i] > xi:\n",
    "#         lam_accept.append( lam[:,i] )\n",
    "#         inds.append(i)\n",
    "\n",
    "# lam_accept = np.array( lam_accept[1::] ).transpose()\n",
    "# num_accept = lam_accept.shape[1]\n",
    "# print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))\n",
    "######\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (18, 6)\n",
    "plt.figure()\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(lam,eta_r)\n",
    "# plt.plot(lam_accept, gkde(lam_accept))\n",
    "plt.scatter(lam0,0.05)\n",
    "# plt.title('Posterior Distribution\\nof Uniform Observed Density \\nwith bound = %1.2e'%uni_max)\n",
    "plt.xlabel('Lambda')\n",
    "pr = 0.2\n",
    "# plt.xlim(lam0*np.array([1-pr,1+pr]))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "x = np.linspace(0,1.1*np.max(q[0]),50)\n",
    "plt.plot(x,pf_dens.evaluate(x))\n",
    "plt.title('Pushforward of Prior')\n",
    "plt.xlabel('Q(lambda)')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "# xx = np.linspace(0,2*uni_max,50)\n",
    "xx = np.linspace(0,np.max(q[0]),50)\n",
    "plt.plot(xx,obs_dens.pdf(xx))\n",
    "plt.title('Observed Density')\n",
    "plt.xlabel('Q(lambda)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# np.exp(t[0])*lam - d[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Visualize Posterior Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_dens_kde = gkde(lam)\n",
    "post_dens_kde = gkde(lam_accept) # Not very useful\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "interact(compare_est_input_dens, x = fixed(x), \n",
    "         estimated_dens1 = fixed(prior_dens_kde), estimated_dens2 = fixed(post_dens_kde), \n",
    "         lab_1 = fixed('KDE prior'), lab_2 = fixed('KDE post'), title=fixed(''),\n",
    "         viewdim=(0, input_dim-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multidimensional Normal\n",
    "\n",
    "# prior_dens = sstats.multivariate_normal( mean = np.zeros(1), cov = np.eye(1) ) # Exact density\n",
    "# interact(compare_input_dens, x = fixed(x), \n",
    "#          analytical_dens = fixed(prior_dens), estimated_dens = fixed(post_dens_kde), \n",
    "#          lab_1 = fixed('prior'), lab_2 = fixed('KDE post'), title = fixed(''),\n",
    "#          viewdim = (0, input_dim-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the push-forward of the posterior using accepted samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1, 100)\n",
    "# x = np.tile(np.linspace(-5,5,100),[output_dim,1])\n",
    "push_post_dens_kde = gkde( QoI_fun(lam_accept) )\n",
    "# Plot the push-forward of the posterior, should look like the observed density\n",
    "# interact(compare_output_dens, x = fixed(x), \n",
    "#          analytical_dens = fixed(obs_dens), estimated_dens = fixed(push_post_dens_kde), \n",
    "#          lab_1 = fixed('observed'), lab_2 = fixed('KDE push'), title = fixed(''),\n",
    "#          viewdim = (0, output_dim-1, 1))\n",
    "compare_output_dens(x,obs_dens, push_post_dens_kde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diagonal crossection view\n",
    "compare_output_dens(x, obs_dens, push_post_dens_kde, \n",
    "                    viewdim = range(output_dim), title = 'Diagonal Cross-Section')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extra visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create KDE of samples on $\\Lambda$ or use specified density on $\\Lambda$\n",
    "\n",
    "***The KDE is not necessary if the density on the input space is already specified***\n",
    "\n",
    "Here, we just do this to show how the density estimator works compared to the exact density.\n",
    "\n",
    "The KDE is not necessary except for the push-forward density. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare KDE of prior to the actual prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interact(compare_input_dens, x = fixed(x), \n",
    "         analytical_dens = fixed(prior_dens), estimated_dens = fixed(prior_dens_kde),\n",
    "         lab_1 = fixed('prior'), lab_2 = fixed('KDE prior'), title = fixed(''),\n",
    "         viewdim = (0, input_dim-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# diagonal crossection view\n",
    "compare_input_dens(x, prior_dens, prior_dens_kde, \n",
    "                   viewdim = range(input_dim), title = 'Diagonal Cross-Section')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
