{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consistent Bayes: Some Motivating Examples\n",
    "---\n",
    "\n",
    "Copyright 2017 Michael Pilosov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_(should be 2.7 and 3.x compatible) _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mathematics and Plotting\n",
    "from HelperFuns import * # pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "# Interactivity\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Some introductory text goes here.   \n",
    "Define $\\Lambda$, $\\mathcal{D}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Sample from $\\Lambda$\n",
    "_Here we implement uniform random priors on the unit hypercube, but you can load in any set of samples in its place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 2 # Specify input space dimension (n)\n",
    "num_samples = int(5E4) # number of input samples (N)\n",
    "lam = np.random.uniform( size = (input_dim, num_samples) ) # generate samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Parameter to Observables (PtO) Map\n",
    "_ Choose from one of the following example options, feel free to add your own _ \n",
    "\n",
    "$O_1(\\lambda) = (\\lambda_1\\times \\frac{1}{2})$  \n",
    "\n",
    "$O_2(\\lambda) = \\sum_{i=1}^n \\lambda_i$  \n",
    "\n",
    "$O_3(\\lambda) = \\lbrace \\lambda_0 - \\lambda_1, \\; \\;\\lambda_1\\rbrace$ \n",
    "\n",
    "$O_4(\\lambda) = \\lbrace \\lambda_0+\\lambda_1, \\; \\lambda_2, \\; \\lambda_3-\\lambda_4 \\rbrace$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def PtO_fun1(lam): # pull first element\n",
    "    return np.array([ 2*lam[0,:] ])\n",
    "\n",
    "def PtO_fun2(lam): # sum all elements\n",
    "    return np.array([ np.sum(lam,axis=0) ])\n",
    "\n",
    "def PtO_fun3(lam): # pull two elements\n",
    "    return np.array([ lam[0,:] - lam[1,:], lam[1,:] ])\n",
    "\n",
    "def PtO_fun4(lam): # three elements\n",
    "    return np.array([ lam[0,:]+lam[1,:], lam[2,:], lam[3,:]-lam[4,:] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PtO_fun_choice = 3\n",
    "\n",
    "if PtO_fun_choice == 1:\n",
    "    PtO_fun = PtO_fun1\n",
    "elif PtO_fun_choice == 2:\n",
    "    PtO_fun = PtO_fun2\n",
    "elif PtO_fun_choice == 3:\n",
    "    PtO_fun = PtO_fun3\n",
    "elif PtO_fun_choice == 4:\n",
    "    PtO_fun = PtO_fun4\n",
    "else:\n",
    "    raise( ValueError('Specify Proper PtO choice!') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute Data Space $O(\\Lambda) = \\mathcal{D}$ \n",
    "\n",
    "Format: `(n_dims, n_samples)`  \n",
    "_Optional_: Specify subset of PtO map's components to use for inversion using the variable `sub_indices` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_full = PtO_fun(lam)\n",
    "sub_indices = None\n",
    "if sub_indices is not None:\n",
    "    D = D_full[sub_indices,:]\n",
    "else:\n",
    "    D = D_full\n",
    "output_dim = D.shape[0]\n",
    "print('dimensions :  lambda = '+str(lam.shape)+'   D = '+str(D.shape)+'   D_full = '+str(D_full.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Push-Forward of the Prior $P_{O(\\Lambda)}$\n",
    "_ ... i.e. Visualize the Data Space_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Below you will find one-dimensional histogram option\n",
    "# M = 100 # number of bins in the data space\n",
    "# plt.hist(D[0],M)\n",
    "# plt.title('histogram of data space')\n",
    "# plt.show()\n",
    "\n",
    "# Interactive Marginal Visualization\n",
    "pf_dens = gkde(D) # compute KDE estimate of it\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "\n",
    "a, b = -0.25, 1.125 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "interact(view_est_dens, x = fixed(plot_grid), \n",
    "         estimated_dens = fixed(pf_dens), \n",
    "         lab = fixed('KDE data'), title=fixed('Pushforward of Prior'),\n",
    "         viewdim=(0, output_dim-1, 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Observed Probability Measure $P_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use multivariate normals because of their common scipy.stats call syntaxes.\n",
    "var_const = 0.1 # constant variance for simplicity\n",
    "cov_matrix = var_const*np.eye(output_dim) # if you want non-constant, use code snippet below\n",
    "# cov_matrix = np.diag( np.round(np.random.rand(1,output_dim),2)[0] ) # random independent covariances\n",
    "means = np.zeros(output_dim) + 0.5 # observed density center (maximum)\n",
    "obs_dens = sstats.multivariate_normal(mean = means, cov = cov_matrix )\n",
    "\n",
    "# For the 1-dimensional case, we can utilize the uniform density.\n",
    "# TODO: generalize uniform box to n-dimensional case\n",
    "# uni_max = 0.5\n",
    "# obs_dens = sstats.uniform(0,uni_max) # 1D only\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "interact(view_analytical_dens, x = fixed(plot_grid), \n",
    "         analytical_dens = fixed(obs_dens), \n",
    "         lab = fixed('KDE data'), title=fixed('Observed $P_\\mathcal{D}$'),\n",
    "         viewdim=(0, output_dim-1, 1) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point we have performed the computations we need to. We have evaluated the input points through our map and performed a KDE on them. It would be useful at this point to save this object and/or its evaluation at every point in the data space for later re-use. Doing so here would be an appropriate place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Accept/reject sampling of posterior\n",
    "\n",
    "Since we have already used the samples in our prior to compute the pushforward density, we can re-use these with an accept/reject algorithm to get a set of samples generated from the posterior according to the solution of the stochastic inverse problem as outlined in the Consistent Bayes formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = []\n",
    "# r = (1./obs_dens.pdf( D )) / pf_dens.evaluate(D) # RECIPRICAL CHI SQUARED. REGULAR IS BELOW.\n",
    "r = obs_dens.pdf( D.transpose() ) / pf_dens.evaluate(D) # vector of ratios evaluated at all the O(lambda)'s\n",
    "M = np.max(r)\n",
    "eta_r = r/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = [i for i in range(num_samples) if eta_r[i] > np.random.uniform(0,1) ]\n",
    "lam_accept = np.array([lam[i,accept_inds] for i in range(input_dim)])\n",
    "num_accept = len(accept_inds)\n",
    "print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Accept/Reject samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "interact(pltaccept, lam = fixed(lam), lam_accept = fixed(lam_accept), \n",
    "         N = (1, num_accept+1, 10), eta_r = fixed(eta_r), \n",
    "         i = (0, input_dim-1, 1), j = (0, input_dim-1, 1))\n",
    "# You will visualize the accepted samples in a subset of size N of the input samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## Visualize Posterior Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dens_kde = gkde(lam)\n",
    "post_dens_kde = gkde(lam_accept)\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "interact(compare_est_input_dens, x = fixed(plot_grid), \n",
    "         estimated_dens1 = fixed(prior_dens_kde), estimated_dens2 = fixed(post_dens_kde), \n",
    "         lab_1 = fixed('KDE prior'), lab_2 = fixed('KDE post'), title=fixed(''),\n",
    "         viewdim=(0, input_dim-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Quality of Solution \n",
    "_We compare the push-forward of the posterior using accepted samples against the observed density_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_post_dens_kde = gkde([D[k][accept_inds] for k in range(output_dim)])\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "\n",
    "# diagonal crossection view\n",
    "interact(compare_output_dens, x = fixed(plot_grid), \n",
    "         analytical_dens = fixed(obs_dens), estimated_dens = fixed(push_post_dens_kde), \n",
    "         lab_1 = fixed('observed'), lab_2 = fixed('KDE push'), title = fixed('Marginal - Observed v. PF'),\n",
    "         viewdim = (0, output_dim-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
