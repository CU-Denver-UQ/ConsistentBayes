{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Time-Series Data in a Consistent Bayesian Framework\n",
    "---\n",
    "\n",
    "Copyright 2017 Michael Pilosov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_(should be 2.7 and 3.x compatible) _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mathematics and Plotting\n",
    "from HelperFuns import * # pyplot wrapper functions useful for visualizations, numpy, scipy, etc.\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "# Interactivity\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Defining the Parameter to Observables (PtO) Map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Consider the Ordinary Differential Equation Initival Value Problem given by  \n",
    "\n",
    "$$\n",
    "\\partial_t u(t) = -u(t) \\\\\n",
    "u(0) = \\lambda_0\n",
    "$$\n",
    "\n",
    "The solution to this problem is $u(t) = \\lambda_0 \\,e^{-t}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $\\lambda_0$ is some uncertain input parameter that we are trying to estimate through experimental observations. \n",
    "\n",
    "Suppose we know that $\\lambda_0 \\in [0, 2]$ with uniform probability and that we hope to infer the parameter by observing the system $u$ at $K+1$ evenly spaced intervals in the interval $[T_0, T]$, where $T > T_0 > 0$. This corresponds to have $K$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define our Parameter-to-Observables Map, we want to transform these observations into a single measurement, which we do by looking at the **Mean Squared Error (2-norm) between the observations and the model predictions**:  \n",
    "\n",
    "$$\n",
    "O(\\lambda) = \\frac{1}{K+1} \\sum_{k=0}^{K+1} \\frac{(\\lambda e^{-(T_0+k\\Delta_t)} - \\lambda_0e^{-(T_0+k\\Delta_t)}) ^ 2}{\\sigma_k^2} = \\frac{1}{K+1}  \\sum_{k=0}^{K} \\frac{( (\\lambda- \\lambda_0) e^{-(T_0+k\\Delta_t)} ) ^ 2 }{ \\sigma_k^2}\n",
    "$$\n",
    "$$\n",
    "= \\frac{(\\lambda- \\lambda_0)^2}{K+1}  \\sum_{k=0}^{K}  \\left ( \\frac{e^{(T_0+k\\Delta_t)}}{\\sigma_k} \\right )^2, \\quad \\text{where } \\Delta_t\\equiv \\frac{T - T_0}{K+1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the division of each measurement by a standard deviation is consistent with the formulation of an additive error statistical model familiar to the usual Bayesian formulation:  \n",
    "\n",
    "$$\n",
    "y_i = \\beta\\, x_i + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### Choose the Reference Parameter\n",
    "_This is what we consider the \"true\" parameter we are trying to estimate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam0 = 0.5 # true / reference lambda_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Experiment\n",
    "- _Set the number of observations you will make, $K$_\n",
    "- _Set the time $T_0$ of the first observation_\n",
    "- _Set the end time $T$ of the last observation_\n",
    "- _Define your confidence in each measurement (standard deviation)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_observations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e10998c72b68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m  \u001b[0;31m# this makes it constant for all of them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# if you want to specify them individually, replace the line below.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msd\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_observations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'num_observations' is not defined"
     ]
    }
   ],
   "source": [
    "dof = 5 # degrees of freedom (K)\n",
    "# if you specify 1, it will occur at T_0\n",
    "T_start = 0.1 # first observation\n",
    "T_end = 1 # last observation\n",
    "# STANDARD DEVIATION FOR EACH MEASUREMENT.\n",
    "sd = 1  # this makes it constant for all of them.\n",
    "# if you want to specify them individually, replace the line below.\n",
    "sigma = sd*np.ones(num_observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use these to construct the map, which we can evaluate by calling `PtO_fun` and passing it a 1-D vector `lambda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = np.linspace(T_start, T_end, int(num_observations))\n",
    "def PtO_fun(lam):\n",
    "    num_observations = dof + 1\n",
    "    return ((lam - lam0)**2/num_observations)*np.sum( [ np.power(\n",
    "        [ np.exp(-t[k])/sigma[k] ], 2)[0] \n",
    "        for k in range(int(num_observations))          ], 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Sample from $\\Lambda$\n",
    "_Here we implement uniform random prior on [0, 1], but you can load in any set of samples in its place._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = int(1E4)\n",
    "input_dim = 1 # do not change. This is for plotting purposes. Unecessary in Sandbox.\n",
    "lam = 2*np.random.uniform( size = (int(input_dim), int(num_samples)) ) # standard uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Compute Data Space $O(\\Lambda) = \\mathcal{D}$ \n",
    "\n",
    "Format: `(n_dims, n_samples)`  \n",
    "_Optional_: Specify subset of PtO map's components to use for inversion using the variable `sub_indices` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = PtO_fun(lam)\n",
    "output_dim = D.shape[0] # This is for plotting purposes. Unecessary in Sandbox.\n",
    "print('dimensions :  lambda = ' + str(lam.shape) + '   D = ' + str(D.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Push-Forward of the Prior $P_{O(\\Lambda)}$\n",
    "_ ... i.e. Visualize the Data Space_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Below you will find one-dimensional histogram option\n",
    "# M = 100 # number of bins in the data space\n",
    "# plt.hist(D[0],M)\n",
    "# plt.title('histogram of data space')\n",
    "# plt.show()\n",
    "\n",
    "# Interactive Marginal Visualization\n",
    "pf_dens = gkde(D) # compute KDE estimate of it\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "\n",
    "a, b = -0.1, 1.25 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "interact(view_est_dens, x = fixed(plot_grid), \n",
    "         estimated_dens = fixed(pf_dens), \n",
    "         lab = fixed('KDE data'), title=fixed('Pushforward of Prior'),\n",
    "         viewdim=(0, output_dim-1, 1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Observed Probability Measure $P_\\mathcal{D}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have assumed an additive normal error model, our data should be distributed according to $d_i \\sim \\chi^2(K)$.  \n",
    "We also include a uniform density on $[0,$ `M` $]$ which is akin to minimizing the MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_dens = sstats.chi2(num_observations)\n",
    "a, b = 0, 1.5 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "# # Uniform Density\n",
    "M = 0.05\n",
    "obs_dens = sstats.uniform(0,M) # 1D only\n",
    "# # A normal density in case you want to invert something else... \n",
    "# obs_dens = sstats.norm(0.5,sigma) # 1D only\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "plt.plot(plot_grid,obs_dens.pdf(plot_grid))\n",
    "# plt.title('Chi Sq, K = %d'%num_observations)\n",
    "plt.title('Observed Density')\n",
    "plt.ylabel('Rel. Freq.')\n",
    "plt.xlabel('d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point we have performed the computations we need to. We have evaluated the input points through our map and performed a KDE on them. It would be useful at this point to save this object and/or its evaluation at every point in the data space for later re-use. Doing so here would be an appropriate place. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## Accept/Reject Sampling of Posterior (with Visualization)\n",
    "\n",
    "Since we have already used the samples in our prior to compute the pushforward density, we can re-use these with an accept/reject algorithm to get a set of samples generated from the posterior according to the solution of the stochastic inverse problem as outlined in the Consistent Bayes formulation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accept_inds = []\n",
    "# r = (1./obs_dens.pdf( D )) / pf_dens.evaluate(D) # RECIPRICAL CHI SQUARED. REGULAR IS BELOW.\n",
    "r = obs_dens.pdf( D ) / pf_dens.evaluate(D) # vector of ratios evaluated at all the O(lambda)'s\n",
    "M = np.max(r)\n",
    "eta_r = r[0]/M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accept_inds = [i for i in range(num_samples) if eta_r[i] > np.random.uniform(0,1) ]\n",
    "lam_accept = np.array([lam[i,accept_inds] for i in range(input_dim)])\n",
    "num_accept = len(accept_inds)\n",
    "print('Number accepted: %d = %2.2f%%'%(num_accept, 100*np.float(num_accept)/num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Accept/Reject samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = 10, 5\n",
    "interact(pltaccept, lam = fixed(lam), lam_accept = fixed(lam_accept), \n",
    "         N = (1, num_accept+1, 10), eta_r = fixed(eta_r), \n",
    "         i = (0, input_dim-1, 1), j = (0, input_dim-1, 1))\n",
    "# You will visualize the accepted samples in a subset of size N of the input samples\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotstuff(lam, lam0, eta_r, res=50, max_x=1.1):\n",
    "    plt.rcParams['figure.figsize'] = (18, 6)\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    x = np.linspace(0, max_x, res)\n",
    "    plt.plot(x,pf_dens.evaluate(x))\n",
    "    plt.title('Pushforward of Prior')\n",
    "    plt.xlabel('O(lambda)')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    xx = np.linspace(0, max_x, res)\n",
    "    plt.plot(xx,obs_dens.pdf(xx))\n",
    "    plt.title('Observed Density')\n",
    "    plt.xlabel('O(lambda)')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.scatter(lam,eta_r)\n",
    "    # plt.plot(lam_accept, gkde(lam_accept))\n",
    "    plt.scatter(lam0, 0.05)\n",
    "    # plt.title('Posterior Distribution\\nof Uniform Observed Density \\nwith bound = %1.2e'%uni_max)\n",
    "    plt.xlabel('Lambda')\n",
    "    # # OPTIONAL:\n",
    "    # pr = 0.2 # percentage view-window around true parameter.\n",
    "    # plt.xlim(lam0*np.array([1-pr,1+pr]))\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plotstuff(lam, lam0, eta_r, res=50, max_x=1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to [Extra Visualizations](#Extra-Visualizations) at the bottom of the worksheet to see the prior compared to the posterior as well as the pushforward of the posterior compared to the observed density. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#Choose-the-Reference-Parameter)\n",
    "\n",
    "--- \n",
    "\n",
    "## Extra Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "### Visualize Posterior Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_dens_kde = gkde(lam)\n",
    "post_dens_kde = gkde(lam_accept)\n",
    "\n",
    "a, b = 0, 1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "# Can plot \"slices\" of densities to observe differences between posterior and prior, but not that useful\n",
    "interact(compare_est_input_dens, x = fixed(plot_grid), \n",
    "         estimated_dens1 = fixed(prior_dens_kde), estimated_dens2 = fixed(post_dens_kde), \n",
    "         lab_1 = fixed('KDE prior'), lab_2 = fixed('KDE post'), title=fixed(''),\n",
    "         viewdim=(0, input_dim-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Quality of Solution \n",
    "_We compare the push-forward of the posterior using accepted samples against the observed density_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push_post_dens_kde = gkde([D[k][accept_inds] for k in range(output_dim)])\n",
    "\n",
    "a, b = 0, 0.1 # linspace parameters for plotting\n",
    "plot_grid = np.linspace(a, b, 100)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 5)\n",
    "# diagonal crossection view\n",
    "interact(compare_output_dens, x = fixed(plot_grid), \n",
    "         analytical_dens = fixed(obs_dens), estimated_dens = fixed(push_post_dens_kde), \n",
    "         lab_1 = fixed('observed'), lab_2 = fixed('KDE push'), title = fixed('Marginal - Observed v. PF'),\n",
    "         viewdim = (0, output_dim-1, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
