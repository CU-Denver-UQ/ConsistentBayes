{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Time-Series Data in a Consistent Bayesian Framework\n",
    "---\n",
    "\n",
    "Copyright 2017 Michael Pilosov\n",
    "\n",
    "Demonstration available at https://www.youtube.com/watch?v=rUIVcl64NXw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "_(should be 2.7 and 3.x compatible) _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mathematics and Plotting\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as sstats\n",
    "from scipy.stats import gaussian_kde as gkde\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.rcParams['figure.figsize'] = 5, 5\n",
    "\n",
    "# Interactivity\n",
    "from ipywidgets import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Defining the Parameter to Observables (PtO) Map "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Consider the Ordinary Differential Equation Initival Value Problem given by  \n",
    "\n",
    "$$\n",
    "\\partial_t u(t) = -u(t) \\\\\n",
    "u(0) = \\lambda_0\n",
    "$$\n",
    "\n",
    "The solution to this problem is $u(t) = \\lambda_0 \\,e^{-t}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose $\\lambda_0$ is some uncertain input parameter that we are trying to estimate through experimental observations. \n",
    "\n",
    "Suppose we know that $\\lambda_0 \\in [0, 2]$ with uniform probability and that we hope to infer the parameter by observing the system $u$ at $K+1$ evenly spaced intervals in the interval $[T_0, T]$, where $T > T_0 > 0$. This corresponds to have $K$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to define our Parameter-to-Observables Map, we want to transform these observations into a single measurement, which we do by looking at the **Mean Squared Error (2-norm) between the observations and the model predictions**:  \n",
    "\n",
    "$$\n",
    "O(\\lambda) = \\frac{1}{K+1} \\sum_{k=0}^{K+1} \\frac{(\\lambda e^{-(T_0+k\\Delta_t)} - \\lambda_0e^{-(T_0+k\\Delta_t)}) ^ 2}{\\sigma_k^2} = \\frac{1}{K+1}  \\sum_{k=0}^{K} \\frac{( (\\lambda- \\lambda_0) e^{-(T_0+k\\Delta_t)} ) ^ 2 }{ \\sigma_k^2}\n",
    "$$\n",
    "$$\n",
    "= \\frac{(\\lambda- \\lambda_0)^2}{K+1}  \\sum_{k=0}^{K}  \\left ( \\frac{e^{(T_0+k\\Delta_t)}}{\\sigma_k} \\right )^2, \\quad \\text{where } \\Delta_t\\equiv \\frac{T - T_0}{K+1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the division of each measurement by a standard deviation is consistent with the formulation of an additive error statistical model familiar to the usual Bayesian formulation:  \n",
    "\n",
    "$$\n",
    "y_i = \\beta\\, x_i + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a step-by-step walkthrough, please see the CBayes_TS.ipynb file.\n",
    "Below you will find an all-in-one version. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Define some functions for the sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sandbox(num_samples = int(1E4), lam_bound = [0,2], lam0=0.5, dof=1,\n",
    "            T=[0.1,1], uncertainty = 0.05, sd = 1):\n",
    "    # NOTE this version only uses constant variances for the sake\n",
    "    # of interactivity.\n",
    "    num_observations = dof + 1\n",
    "    sigma = sd*np.ones(num_observations)\n",
    "    T_start, T_end = T\n",
    "    if T_end < T_start:\n",
    "        print('Error: end time is before start time. Switching them now.')\n",
    "        T_temp = T_end\n",
    "        T_end = T_start\n",
    "        T_start = T_temp\n",
    "    if num_observations == 1:\n",
    "        print('K=0 specified, This is a single observation at t = %f.'%T_start)\n",
    "    t = np.linspace(T_start, T_end, num_observations)\n",
    "    def PtO_fun(lam):\n",
    "        return ((lam - lam0)**2/num_observations)*np.sum( [ np.power(\n",
    "            [ np.exp(-t[k])/sigma[k] ], 2)[0] \n",
    "            for k in range(int(num_observations))          ], 0 )\n",
    "    \n",
    "    # Sample the Parameter Space\n",
    "    a, b = lam_bound\n",
    "    lam = np.random.uniform(a, b, size = (1, int(num_samples)) ) # standard uniform\n",
    "    # Map to Data Space\n",
    "    D = PtO_fun(lam)\n",
    "#     print('dimensions :  lambda = ' + str(lam.shape) + '   D = ' + str(D.shape) )\n",
    "    # Perform KDE to estimate the pushforward\n",
    "    pf_dens = gkde(D) # compute KDE estimate of it\n",
    "    # Specify Observed Measure - Uniform Density\n",
    "    \n",
    "    obs_dens = sstats.uniform(0,uncertainty) # 1D only\n",
    "    # Solve the problem\n",
    "    r = obs_dens.pdf( D ) / pf_dens.evaluate(D) # vector of ratios evaluated at all the O(lambda)'s\n",
    "    M = np.max(r)\n",
    "    eta_r = r[0]/M\n",
    "    print('\\tEntropy is %1.4e'%sstats.entropy(eta_r))\n",
    "    res = 50;\n",
    "    max_x = 3;\n",
    "    # Plot stuff\n",
    "    plt.rcParams['figure.figsize'] = (18, 6)\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 3, 1)\n",
    "    x = np.linspace(-0.25, max_x, res)\n",
    "    plt.plot(x, pf_dens.evaluate(x))\n",
    "    plt.title('Pushforward of Prior')\n",
    "    plt.xlabel('O(lambda)')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    xx = np.linspace(0, 0.5, res)\n",
    "    plt.plot(xx, obs_dens.pdf(xx))\n",
    "    plt.title('Observed Density')\n",
    "    plt.xlabel('O(lambda)')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.scatter(lam, eta_r)\n",
    "    # plt.plot(lam_accept, gkde(lam_accept))\n",
    "    plt.scatter(lam0, 0.05)\n",
    "    plt.title('Posterior Distribution') #\\nof Uniform Observed Density \\nwith bound = %1.2e'%uncertainty)\n",
    "    plt.xlabel('Lambda')\n",
    "#     plt.title('$\\eta_r$')\n",
    "    # # OPTIONAL:\n",
    "    # pr = 0.2 # percentage view-window around true parameter.\n",
    "#     plt.xlim(lam0*np.array([1-pr,1+pr]))\n",
    "    plt.xlim([a,b])\n",
    "    plt.show()\n",
    "    \n",
    "#     return eta_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# All-in-One Sandbox!\n",
    "_Run the cells below to start experimenting_\n",
    "All the underscores are because I named lists as those objects, which disabled autocomplete. So I use the widget here with the same name to figure out the syntax, then add in the `[k]` index e.g. `num_samples[0].value()` afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_num_samples = widgets.IntSlider(value=1000, continuous_update=False, orientation='vertical',\n",
    "    min=int(5E2), max=int(5E4), step=500, description='$N$ :')\n",
    "\n",
    "_lam_bound = widgets.FloatRangeSlider(value=[0.0, 2.0], continuous_update=False, orientation='horizontal',\n",
    "    min=-5.0, max = 5.0, step=0.25, description='Param: $\\Lambda \\in$')\n",
    "\n",
    "_lam0 = widgets.FloatSlider(value=1.0, continuous_update=False, orientation='horizontal',\n",
    "    min=0.25, max=1.75, step=0.05, description='IC: $\\lambda_0$')\n",
    "\n",
    "def update_lam0_range(*args): # update ref lambda if lambda bound changes\n",
    "    _lam0.min = _lam_bound.value[0]\n",
    "    _lam0.max = _lam_bound.value[1]\n",
    "_lam_bound.observe(update_lam0_range, 'value')\n",
    "\n",
    "_dof = widgets.IntSlider(value=0, continuous_update=False, orientation='horizontal',\n",
    "    min=0, max=50, description='d.o.f: $K$ =')\n",
    "\n",
    "_T = widgets.FloatRangeSlider( value=[0.5, 1], min=0.1, max=7.5, step=0.1, continuous_update=False,\n",
    "    description='$t\\in [T_0, T]$ :', orientation='horizontal',\n",
    "    readout=True, readout_format='.1f')\n",
    "\n",
    "_uncertainty = widgets.FloatSlider(value=0.01, continuous_update=False, orientation='vertical',\n",
    "    min=0.005, max=0.25, step=0.005, \n",
    "    description='$\\epsilon$ :', readout_format='.3f')\n",
    "\n",
    "_sd = widgets.FloatSlider(value=1, continuous_update=False, orientation='vertical',\n",
    "    min=0.15, max=1.85, step=0.05, description='$\\sigma$ :')\n",
    "\n",
    "_lbl = widgets.Label(\"UQ Sandbox\", disabled=False)\n",
    "_u1 = widgets.VBox([_lbl, _lam_bound, _lam0, _dof, _T])\n",
    "_u2 = widgets.HBox([_num_samples, _uncertainty, _sd])\n",
    "# u3 = widgets.HBox([uncertainty, sd])\n",
    "_ui = widgets.HBox([_u1, _u2])\n",
    "_u1.layout.justify_content = 'center'\n",
    "_ui.layout.justify_content = 'center'\n",
    "\n",
    "\n",
    "_out = interactive_output(sandbox, {'num_samples': _num_samples, \n",
    "                        'lam_bound': _lam_bound, \n",
    "                        'lam0': _lam0, \n",
    "                        'dof': _dof, \n",
    "                        'T': _T,\n",
    "                        'uncertainty': _uncertainty, \n",
    "                         'sd': _sd} )\n",
    "display(_ui, _out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Suggestions\n",
    "\n",
    "- Increase $N$ and watch the Pushforward of the Prior change/converge.\n",
    "- If you broaden the standard deviation $\\sigma$, we suggest to also broaden the bound on the parameter space $\\Lambda$ in order to avoid voilating the predictability assumption.\n",
    "- Notice the relationship between the bound on the interval we are inverting for the Mean Squared Error and the support of the posterior.\n",
    "- The same happens as you increase $\\sigma$.\n",
    "- Change the initial condition $\\lambda_0$ and watch the posterior distribution follow the slider.\n",
    "\n",
    "\n",
    "\n",
    "- Fix the number of observations to 1 and change the interval over which the observation is being made (with $K=0$, the observation occurs only at $T_0$). Notice the diminishing returns as you wait to make your measurement. \n",
    "- Fix some interval and change the number of observations made during this time period.\n",
    "- Fix a number of observations (several) and fix $T_0$ while changing $T$ to observe another example of diminshing returns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Entropy barely changes as $\\lambda_0$ moves around. Increases a bit near boundary of $\\Lambda$ (likely due to predictability assumption being violated)\n",
    "- For a wide time measurement window, entropy increases with the number of observations $K$ (d.o.f.)\n",
    "- Widening $\\Lambda$ decreases entropy, obviously enlarges $\\mathcal{D}$, support of $P_\\mathcal{D}$.\n",
    "- If you narrow the window, the entropy decreases.\n",
    "- As the window slides earlier in time, the entropy decreases.\n",
    "- Higher MSE threshold ($\\epsilon$, support of observed density) means higher entropy.\n",
    "- Higher variance means higher entropy. We might run a suite of $\\sigma$s MADS-style to study the robustness of a design. \n",
    "    - perhaps if we try to minimize entropy (maximize information gain), we look for designs that are less sensitive to the choice of $\\sigma$s, which would **correspond to an experimental design that is robust to measurement uncertainty.**\n",
    "- Increasing the number of samples $N$ increases entropy quite a bit. Would like to figure out a way to control for this? _Is it even right to be using `scipy.stats.entropy`?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(_ui, _out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Work in progress below\n",
    "\n",
    "---\n",
    "\n",
    "## Experiments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_experiments = 5\n",
    "\n",
    "# We create many copies of the same widget objects in order to isolate our experimental areas.\n",
    "num_samples = [widgets.IntSlider(value=1000, continuous_update=False, orientation='vertical',\n",
    "    min=int(5E2), max=int(1E4), step=500, description='$N$ :') for k in range(num_experiments)]\n",
    "lam_bound = [widgets.FloatRangeSlider(value=[0.0, 2.0], continuous_update=False, orientation='horizontal',\n",
    "    min=-5.0, max = 5.0, step=0.25, description='Param: $\\Lambda \\in$') for k in range(num_experiments)]\n",
    "lam0 = [widgets.FloatSlider(value=1.0, continuous_update=False, orientation='horizontal',\n",
    "    min=0.25, max=1.75, step=0.05, description='IC: $\\lambda_0$') for k in range(num_experiments)]\n",
    "dof = [widgets.IntSlider(value=0, continuous_update=False, orientation='horizontal',\n",
    "    min=0, max=50, description='d.o.f: $K$ =') for k in range(num_experiments)]\n",
    "T = [widgets.FloatRangeSlider( value=[0.5, 1], min=0.1, max=7.5, step=0.1, continuous_update=False,\n",
    "    description='$t\\in [T_0, T]$ :', orientation='horizontal',\n",
    "    readout=True, readout_format='.1f') for k in range(num_experiments)]\n",
    "uncertainty = [widgets.FloatSlider(value=0.01, continuous_update=False, orientation='vertical',\n",
    "    min=0.005, max=0.25, step=0.005,\n",
    "    description='$\\epsilon$ :', readout_format='.3f') for k in range(num_experiments)]\n",
    "sd = [widgets.FloatSlider(value=1, continuous_update=False, orientation='vertical',\n",
    "    min=0.15, max=1.85, step=0.05, description='$\\sigma$ :') for k in range(num_experiments)]\n",
    "                          \n",
    "D = [ {'num_samples': num_samples[k], \n",
    "         'lam_bound': lam_bound[k], \n",
    "         'lam0': lam0[k], \n",
    "         'dof': dof[k], \n",
    "         'T': T[k],\n",
    "         'uncertainty': uncertainty[k], \n",
    "         'sd': sd[k]} for k in range(num_experiments)] \n",
    "\n",
    "\n",
    "out = [interactive_output(sandbox, D[k]) for k in range(num_experiments)]\n",
    "                          \n",
    "def update_lam0(*args):\n",
    "    k = tab_nest.selected_index\n",
    "    lam0[k].min = lam_bound[k].value[0]\n",
    "    lam0[k].max = lam_bound[k].value[1]\n",
    "#     def update_lam0_range(): # update ref lambda if lambda bound changes\n",
    "#         lam0[k].min = lam_bound[k].value[0]\n",
    "#         lam0[k].max = lam_bound[k].value[1]\n",
    "#     return update_lam0_range\n",
    "# L = {}\n",
    "# Bind Updates for linked sliders\n",
    "[lam_bound[k].observe(update_lam0, 'value') for k in range(num_experiments)]\n",
    "\n",
    "\n",
    "# User Interface\n",
    "lbl = widgets.Label(\"UQ Sandbox\", disabled=False)\n",
    "\n",
    "u1 = [widgets.VBox([lbl, lam_bound[k], lam0[k], dof[k], T[k]]) for k in range(num_experiments)]\n",
    "for k in range(num_experiments):\n",
    "    u1[k].layout.justify_content = 'center'\n",
    "u2 = [widgets.HBox([num_samples[k], uncertainty[k], sd[k]]) for k in range(num_experiments)]\n",
    "ui = [widgets.HBox([u1[k], u2[k]]) for k in range(num_experiments)]\n",
    "# lam_bound[k].observe(L[str(k)], 'value') \n",
    "    \n",
    "# Create our pages\n",
    "pages = [widgets.HBox() for k in range(num_experiments)]\n",
    "\n",
    "# instantiate notebook with tabs (accordions) representing experiments\n",
    "tab_nest = widgets.Tab()\n",
    "tab_nest.children = [pages[k] for k in range(num_experiments)]\n",
    "\n",
    "# title your notebooks\n",
    "experiment_names = ['Experiment %d'%k for k in range(num_experiments)]\n",
    "for k in range(num_experiments):\n",
    "    tab_nest.set_title(k, experiment_names[k])\n",
    "\n",
    "# Spawn the children\n",
    "for k in range(num_experiments):\n",
    "    tab_nest.children[k].children = [widgets.VBox([ui[k], out[k]])]\n",
    "\n",
    "# Display the \"tabulated nest\"\n",
    "tab_nest"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],

   "source": [
    "# Now that everything has been created, we can start tweaking our experiments.\n",
    "# Commands like the one below can be put into accordions or new tabs as checkboxes.\n",
    "\n",
    "# this is now how you can disable individual sliders.\n",
    "dof[0].disabled = True \n",
    "\n",
    "# this is how you can manually write a value\n",
    "dof[0].set_trait('value', 5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can grab individual elements and control them here instead, \n",
    "# the tabs above will react.\n",
    "tab_nest.children[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tab_nest.selected_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam_bound[1].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam_bound[1].keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
